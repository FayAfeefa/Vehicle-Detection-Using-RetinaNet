# -*- coding: utf-8 -*-
"""videotest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17g0U_kMmlM_juUYjSexNcTPIEI_IWac2
"""

import os
import time
import tensorflow as tf
import cv2
import numpy as np

from object_detection.utils import label_map_util
from PIL import Image
#from google.colab.patches import cv2_imshow
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils

from IPython.display import HTML
from base64 import b64encode

#Path to saved model

PATH_TO_SAVED_MODEL = "/kaggle/working/inference_graph/saved_model"

# Load label map and obtain class names and ids
#label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
category_index=label_map_util.create_category_index_from_labelmap("/kaggle/input/images2/images/labelmap.pbtxt",use_display_name=True)
num_detect = [0,0,0,0]

def visualise_on_image(image, bboxes, labels, scores, thresh):
    (h, w, d) = image.shape
    for bbox, label, score in zip(bboxes, labels, scores):
        if score > thresh:
            xmin, ymin = int(bbox[1]*w), int(bbox[0]*h)
            xmax, ymax = int(bbox[3]*w), int(bbox[2]*h)

            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0,255,0), 2)
            cv2.putText(image, f"{label}: {int(score*100)} %", (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 2)
            if label == "R02":
              num_detect[0] += 1
              cv2.putText(image, f"1: {num_detect[0]}", (50,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)
            if label == "R03":
              num_detect[1] += 1
              cv2.putText(image, f"2: {num_detect[1]}", (60,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)
            if label == "L00":
              num_detect[2] += 1
              cv2.putText(image, f"3: {num_detect[2]}", (70,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)
            if label == "00":
              num_detect[3] += 1
              cv2.putText(image, f"4: {num_detect[3]}", (80,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)
            #print(label)
            #print(type(label))
    return image

if __name__ == '__main__':

    # Load the model
    print("Loading saved model ...")
    detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)
    print("Model Loaded!")

    # Video Capture (video_file)
    video_capture = cv2.VideoCapture("/kaggle/input/videotesting/output_test.avi")
    start_time = time.time()

    frame_width = int(video_capture.get(3))
    frame_height = int(video_capture.get(4))
    #fps = int(video_capture.get(5))
    size = (frame_width, frame_height)

    #Initialize video writer
    result = cv2.VideoWriter('/kaggle/working/output_test.avi', cv2.VideoWriter_fourcc(*'MJPG'),15, size)

    while True:
      ret, frame = video_capture.read()
      if not ret:
          print('Unable to read video / Video ended')
          break

      frame = cv2.flip(frame, 1)
      image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
      # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
      # The model expects a batch of images, so also add an axis with `tf.newaxis`.
      input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]

      # Pass frame through detector
      detections = detect_fn(input_tensor)

      # Set detection parameters

      score_thresh = 0.4   # Minimum threshold for object detection
      max_detections = 100

      # All outputs are batches tensors.
      # Convert to numpy arrays, and take index [0] to remove the batch dimension.
      # We're only interested in the first num_detections.
      scores = detections['detection_scores'][0, :max_detections].numpy()
      bboxes = detections['detection_boxes'][0, :max_detections].numpy()
      labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)
      labels = [category_index[n]['name'] for n in labels]

      # Display detections
      visualise_on_image(frame, bboxes, labels, scores, score_thresh)

      end_time = time.time()
      fps = int(1/(end_time - start_time))
      start_time = end_time
      cv2.putText(frame, f"FPS: {fps}", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)
      #cv2_imshow(frame)
      #print ([category_index.get(value) for index,value in enumerate(labels[0]) if scores[0] > 0.4])
      #Write output video
      result.write(frame)

    for i in num_detect:
        print(i, end=" ")
    video_capture.release()