{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls ../../..","metadata":{"id":"lw5hWsmdB5QT","outputId":"ab5f7346-5ce5-4e77-b180-63da700a9742","_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-10-18T01:19:11.807267Z","iopub.execute_input":"2023-10-18T01:19:11.807594Z","iopub.status.idle":"2023-10-18T01:19:12.772538Z","shell.execute_reply.started":"2023-10-18T01:19:11.807572Z","shell.execute_reply":"2023-10-18T01:19:12.771705Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"'=2.*'\t\t\t      libnvinfer8_8.0.0-1+cuda11.0_amd64.deb\n'=2023.0.1'\t\t      libx32\n NGC-DL-CONTAINER-LICENSE     media\n bin\t\t\t      mnt\n boot\t\t\t      opt\n cuda-keyring_1.0-1_all.deb   proc\n dev\t\t\t      root\n entrypoint.sh\t\t      run\n etc\t\t\t      run_jupyter.sh\n home\t\t\t      sbin\n install_packages.sh\t      srv\n kaggle\t\t\t      sys\n lib\t\t\t      tmp\n lib32\t\t\t      usr\n lib64\t\t\t      var\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow-object-detection-api","metadata":{"id":"xtRMpbszCIN5","outputId":"1ddb8857-2dba-4a30-e74f-b030a08f9892","execution":{"iopub.status.busy":"2023-10-18T01:19:12.774178Z","iopub.execute_input":"2023-10-18T01:19:12.774540Z","iopub.status.idle":"2023-10-18T01:19:27.677391Z","shell.execute_reply.started":"2023-10-18T01:19:12.774516Z","shell.execute_reply":"2023-10-18T01:19:27.676498Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tensorflow-object-detection-api\n  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (9.5.0)\nRequirement already satisfied: Matplotlib>=2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (3.7.2)\nRequirement already satisfied: Cython>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (0.29.35)\nRequirement already satisfied: Protobuf in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (3.20.3)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (4.9.3)\nCollecting jupyter (from tensorflow-object-detection-api)\n  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (2.12.0)\nCollecting contextlib2 (from tensorflow-object-detection-api)\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from tensorflow-object-detection-api) (0.40.0)\nCollecting twine (from tensorflow-object-detection-api)\n  Downloading twine-4.0.2-py3-none-any.whl (36 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.4.4)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (21.3)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.2)\nRequirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (6.5.4)\nRequirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (5.4.4)\nRequirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (6.6.3)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (6.4.5)\nRequirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (6.23.3)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from jupyter->tensorflow-object-detection-api) (7.7.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (3.9.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (0.4.13)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (16.0.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (68.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (4.6.3)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->tensorflow-object-detection-api) (0.32.0)\nCollecting pkginfo>=1.8.1 (from twine->tensorflow-object-detection-api)\n  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\nCollecting readme-renderer>=35.0 (from twine->tensorflow-object-detection-api)\n  Downloading readme_renderer-42.0-py3-none-any.whl (13 kB)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (2.31.0)\nRequirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (0.10.1)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (1.26.15)\nRequirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (6.7.0)\nRequirement already satisfied: keyring>=15.1 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (24.2.0)\nCollecting rfc3986>=1.4.0 (from twine->tensorflow-object-detection-api)\n  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: rich>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from twine->tensorflow-object-detection-api) (13.4.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.15.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->tensorflow-object-detection-api) (0.2.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->tensorflow-object-detection-api) (1.11.2)\nRequirement already satisfied: jaraco.classes in /opt/conda/lib/python3.10/site-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (3.2.3)\nRequirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.10/site-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (3.3.3)\nRequirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (0.8.0)\nCollecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->tensorflow-object-detection-api)\n  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: docutils>=0.13.1 in /opt/conda/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (0.20.1)\nRequirement already satisfied: Pygments>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (2.15.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2023.7.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12.0.0->twine->tensorflow-object-detection-api) (2.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (2.3.7)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (0.1.3)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.6.7)\nRequirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (8.14.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.1)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (1.5.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.9.3)\nRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (25.1.0)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.3.2)\nRequirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.9.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.6.5)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.0.7)\nRequirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (3.0.38)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.1.2)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.2.2)\nRequirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (5.9.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (2.1.3)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter->tensorflow-object-detection-api) (21.3.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.17.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.17.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.0.0)\nRequirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (2.4.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (1.3.1)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.18.2)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->tensorflow-object-detection-api) (3.10.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->tensorflow-object-detection-api) (0.1.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (2.6.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (0.2.3)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (2.17.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (4.17.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.6)\nRequirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (38.0.4)\nRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->tensorflow-object-detection-api) (21.2.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter->tensorflow-object-detection-api) (2.3.2.post1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from jaraco.classes->keyring>=15.1->twine->tensorflow-object-detection-api) (9.1.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (1.15.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.3)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (0.19.3)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (3.7.0)\nRequirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (0.6.3)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (0.4.4)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (6.5.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (1.6.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->tensorflow-object-detection-api) (3.2.2)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.2)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (6.0)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tensorflow-object-detection-api) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (2.0)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter->tensorflow-object-detection-api) (1.2.3)\nBuilding wheels for collected packages: tensorflow-object-detection-api\n  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844490 sha256=41c6bb64b344d0ad7cf99051081dd69ab278a58277f62157e03129cdfaf76819\n  Stored in directory: /root/.cache/pip/wheels/8a/55/68/c084bc2cd93c41fd8f7e2ef9e6bbcb2c35a3e4b49e42044d02\nSuccessfully built tensorflow-object-detection-api\nInstalling collected packages: nh3, rfc3986, readme-renderer, pkginfo, contextlib2, twine, jupyter, tensorflow-object-detection-api\nSuccessfully installed contextlib2-21.6.0 jupyter-1.0.0 nh3-0.2.14 pkginfo-1.9.6 readme-renderer-42.0 rfc3986-2.0.0 tensorflow-object-detection-api-0.1.1 twine-4.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"id":"0_BVaIP_CkVG","outputId":"2b13af1e-9fe4-44eb-f9b6-9de53cdb1c5a","execution":{"iopub.status.busy":"2023-10-18T01:19:27.678903Z","iopub.execute_input":"2023-10-18T01:19:27.679167Z","iopub.status.idle":"2023-10-18T01:19:36.600997Z","shell.execute_reply.started":"2023-10-18T01:19:27.679144Z","shell.execute_reply":"2023-10-18T01:19:36.600165Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/tensorflow/models","metadata":{"id":"M0lWrLwVCooU","outputId":"91d46975-40a1-4338-989a-39beb8c1ed8b","execution":{"iopub.status.busy":"2023-10-18T01:19:36.602768Z","iopub.execute_input":"2023-10-18T01:19:36.603266Z","iopub.status.idle":"2023-10-18T01:19:56.034186Z","shell.execute_reply.started":"2023-10-18T01:19:36.603241Z","shell.execute_reply":"2023-10-18T01:19:56.033253Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cloning into 'models'...\nremote: Enumerating objects: 88011, done.\u001b[K\nremote: Counting objects: 100% (1723/1723), done.\u001b[K\nremote: Compressing objects: 100% (706/706), done.\u001b[K\nremote: Total 88011 (delta 1110), reused 1570 (delta 999), pack-reused 86288\u001b[K\nReceiving objects: 100% (88011/88011), 601.16 MiB | 44.93 MiB/s, done.\nResolving deltas: 100% (63008/63008), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/\n!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n!rm ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz","metadata":{"id":"6Zh5JTKyFJ8r","outputId":"8c9834df-8dad-4572-e243-749a608faf98","execution":{"iopub.status.busy":"2023-10-18T01:19:56.035626Z","iopub.execute_input":"2023-10-18T01:19:56.035879Z","iopub.status.idle":"2023-10-18T01:20:05.609799Z","shell.execute_reply.started":"2023-10-18T01:19:56.035856Z","shell.execute_reply":"2023-10-18T01:20:05.608444Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n--2023-10-18 01:19:56--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\nResolving download.tensorflow.org (download.tensorflow.org)... 64.233.183.207, 173.194.194.207, 173.194.195.207, ...\nConnecting to download.tensorflow.org (download.tensorflow.org)|64.233.183.207|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 386527459 (369M) [application/x-tar]\nSaving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n\nssd_resnet101_v1_fp 100%[===================>] 368.62M   165MB/s    in 2.2s    \n\n2023-10-18 01:19:59 (165 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\nssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/models/research\n!protoc object_detection/protos/*.proto --python_out=.\n# Install TensorFlow Object Detection API.\n!cp object_detection/packages/tf2/setup.py .\n!python -m pip install .\n!pip install tensorflow==2.13.0","metadata":{"id":"L6WGacceIRAG","outputId":"ee182f19-e191-4ea3-f780-d3cf10863bdf","execution":{"iopub.status.busy":"2023-10-18T01:20:05.611490Z","iopub.execute_input":"2023-10-18T01:20:05.611732Z","iopub.status.idle":"2023-10-18T01:22:26.196127Z","shell.execute_reply.started":"2023-10-18T01:20:05.611710Z","shell.execute_reply":"2023-10-18T01:22:26.195121Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/models/research\nProcessing /kaggle/working/models/research\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting avro-python3 (from object-detection==0.1)\n  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (2.46.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (9.5.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (4.9.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (3.7.2)\nRequirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (0.29.35)\nRequirement already satisfied: contextlib2 in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (21.6.0)\nCollecting tf-slim (from object-detection==0.1)\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (1.16.0)\nCollecting pycocotools (from object-detection==0.1)\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lvis (from object-detection==0.1)\n  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (1.11.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (2.0.2)\nCollecting tf-models-official>=2.5.1 (from object-detection==0.1)\n  Downloading tf_models_official-2.14.2-py2.py3-none-any.whl (2.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow_io in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (0.32.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from object-detection==0.1) (2.12.0)\nCollecting pyparsing==2.4.7 (from object-detection==0.1)\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.6)\nCollecting gin-config (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.97.0)\nCollecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\nRequirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\nRequirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.76)\nRequirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.3)\nRequirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\nCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\nCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorflow-text~=2.14.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tensorflow~=2.14.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2023.3)\nRequirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (1.4.0)\nRequirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.20.3)\nRequirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7)\nRequirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.9.1)\nCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.2.1)\nRequirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7.4)\nRequirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.18)\nRequirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.51.1)\nRequirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.7.0)\nRequirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.21.0)\nRequirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.6.1)\nRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.13.0)\nRequirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.22.3)\nRequirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\nRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.6.3)\nRequirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.19.0)\nCollecting pyarrow<10.0.0,>=3.0.0 (from apache-beam->object-detection==0.1)\n  Downloading pyarrow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object-detection==0.1) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from lvis->object-detection==0.1) (1.4.4)\nRequirement already satisfied: opencv-python>=4.1.0.25 in /opt/conda/lib/python3.10/site-packages (from lvis->object-detection==0.1) (4.8.0.76)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (1.1.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (4.40.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (21.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_io->object-detection==0.1) (0.32.0)\nRequirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.20.0)\nRequirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\nRequirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.0)\nRequirement already satisfied: ml-dtypes==0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (68.0.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\nCollecting tensorboard<2.15,>=2.14 (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting keras (from object-detection==0.1)\n  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\nCollecting tensorflow-hub>=0.6.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.7)\nRequirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\nRequirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.12.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.15.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.59.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.7)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\nBuilding wheels for collected packages: object-detection, avro-python3, dill, seqeval\n  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21878674 sha256=7984dc37f03750ccaa1b2bde5ce2160eb595134f4b303ed42e5984b01d6882a0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-r1m516ud/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\n  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=223b1a13cb61a662610c312d440dac0d6fc6e821a76986e72f68d80cacbf9f9e\n  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n  Building wheel for dill (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=fd7cefa30a172bbacc3d7080177bfeff0e1581c27de1706b3d18f4a05bdd7587\n  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=6c6d481e8f566d78653aaab0f80eec6b92f306b740b1170d058b5540f04cf5e6\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built object-detection avro-python3 dill seqeval\nInstalling collected packages: gin-config, tf-slim, tensorflow-model-optimization, tensorflow-hub, tensorflow-estimator, pyparsing, pyarrow, portalocker, keras, immutabledict, dill, avro-python3, sacrebleu, seqeval, tensorboard, pycocotools, lvis, tensorflow, tensorflow-text, tf-models-official, object-detection\n  Attempting uninstall: tensorflow-hub\n    Found existing installation: tensorflow-hub 0.12.0\n    Uninstalling tensorflow-hub-0.12.0:\n      Successfully uninstalled tensorflow-hub-0.12.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.12.0\n    Uninstalling tensorflow-estimator-2.12.0:\n      Successfully uninstalled tensorflow-estimator-2.12.0\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.0.9\n    Uninstalling pyparsing-3.0.9:\n      Successfully uninstalled pyparsing-3.0.9\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 11.0.0\n    Uninstalling pyarrow-11.0.0:\n      Successfully uninstalled pyarrow-11.0.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.12.0\n    Uninstalling keras-2.12.0:\n      Successfully uninstalled keras-2.12.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.7\n    Uninstalling dill-0.3.7:\n      Successfully uninstalled dill-0.3.7\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.12.3\n    Uninstalling tensorboard-2.12.3:\n      Successfully uninstalled tensorboard-2.12.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.12.0\n    Uninstalling tensorflow-2.12.0:\n      Successfully uninstalled tensorflow-2.12.0\n  Attempting uninstall: tensorflow-text\n    Found existing installation: tensorflow-text 2.12.1\n    Uninstalling tensorflow-text-2.12.1:\n      Successfully uninstalled tensorflow-text-2.12.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 9.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\nmultiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\npathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\npytoolconfig 1.2.5 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\ntensorflow-decision-forests 1.4.0 requires tensorflow~=2.12.0, but you have tensorflow 2.14.0 which is incompatible.\ntensorflowjs 3.15.0 requires tensorflow-hub<0.13,>=0.7.0, but you have tensorflow-hub 0.15.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed avro-python3-1.10.2 dill-0.3.1.1 gin-config-0.5.0 immutabledict-3.0.0 keras-2.14.0 lvis-0.5.3 object-detection-0.1 portalocker-2.8.2 pyarrow-9.0.0 pycocotools-2.0.7 pyparsing-2.4.7 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-hub-0.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.14.0 tf-models-official-2.14.2 tf-slim-1.1.0\nCollecting tensorflow==2.13.0\n  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.9.0)\nCollecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (16.0.0)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (68.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.16.0)\nCollecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (2.3.0)\nCollecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.32.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.13.0) (2.4.7)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\nInstalling collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.6.3\n    Uninstalling typing_extensions-4.6.3:\n      Successfully uninstalled typing_extensions-4.6.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.14.0\n    Uninstalling tensorflow-estimator-2.14.0:\n      Successfully uninstalled tensorflow-estimator-2.14.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.14.0\n    Uninstalling keras-2.14.0:\n      Successfully uninstalled keras-2.14.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.14.1\n    Uninstalling tensorboard-2.14.1:\n      Successfully uninstalled tensorboard-2.14.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.14.0\n    Uninstalling tensorflow-2.14.0:\n      Successfully uninstalled tensorflow-2.14.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nchex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 9.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\npydantic-core 2.6.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\ntensorflow-decision-forests 1.4.0 requires tensorflow~=2.12.0, but you have tensorflow 2.13.0 which is incompatible.\ntensorflow-text 2.14.0 requires tensorflow<2.15,>=2.14.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\ntensorflowjs 3.15.0 requires tensorflow-hub<0.13,>=0.7.0, but you have tensorflow-hub 0.15.0 which is incompatible.\ntf-models-official 2.14.2 requires tensorflow~=2.14.0, but you have tensorflow 2.13.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/builders/model_builder_tf2_test.py","metadata":{"id":"6Uc2JSq6IaQI","outputId":"2aa081dd-ab0a-432c-b3ad-c1c16297b314","execution":{"iopub.status.busy":"2023-10-18T01:22:26.197537Z","iopub.execute_input":"2023-10-18T01:22:26.197776Z","iopub.status.idle":"2023-10-18T01:23:06.919965Z","shell.execute_reply.started":"2023-10-18T01:22:26.197752Z","shell.execute_reply":"2023-10-18T01:23:06.918976Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nRunning tests under Python 3.10.12: /opt/conda/bin/python\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\nW1018 01:22:35.146181 133248269272896 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n/opt/conda/lib/python3.10/site-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n  logging.warn(('Building experimental DeepMAC meta-arch.'\nW1018 01:22:35.439356 133248269272896 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\nI1018 01:22:35.756768 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.37s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\nI1018 01:22:36.414572 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.66s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\nI1018 01:22:36.763859 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\nI1018 01:22:37.206501 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.44s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\nI1018 01:22:39.216846 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.01s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\nI1018 01:22:39.223232 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\nI1018 01:22:39.250468 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\nI1018 01:22:39.268290 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\nI1018 01:22:39.286310 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\nI1018 01:22:39.394155 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\nI1018 01:22:39.498292 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\nI1018 01:22:39.606905 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\nI1018 01:22:39.715808 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\nI1018 01:22:39.819123 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\nI1018 01:22:39.850486 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\nI1018 01:22:40.047767 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\nI1018 01:22:40.047952 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\nI1018 01:22:40.048031 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\nI1018 01:22:40.050641 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:40.079813 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:40.079993 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:40.157887 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:40.158082 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:40.354522 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:40.354724 133248269272896 efficientnet_model.py:143] round_filter input=40 output=40\nI1018 01:22:40.535970 133248269272896 efficientnet_model.py:143] round_filter input=40 output=40\nI1018 01:22:40.536135 133248269272896 efficientnet_model.py:143] round_filter input=80 output=80\nI1018 01:22:40.808125 133248269272896 efficientnet_model.py:143] round_filter input=80 output=80\nI1018 01:22:40.808354 133248269272896 efficientnet_model.py:143] round_filter input=112 output=112\nI1018 01:22:41.078026 133248269272896 efficientnet_model.py:143] round_filter input=112 output=112\nI1018 01:22:41.078236 133248269272896 efficientnet_model.py:143] round_filter input=192 output=192\nI1018 01:22:41.438028 133248269272896 efficientnet_model.py:143] round_filter input=192 output=192\nI1018 01:22:41.438247 133248269272896 efficientnet_model.py:143] round_filter input=320 output=320\nI1018 01:22:41.524711 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=1280\nI1018 01:22:41.754529 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:41.809280 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\nI1018 01:22:41.809515 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\nI1018 01:22:41.811575 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\nI1018 01:22:41.813774 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:41.833502 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:41.833650 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:41.980450 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:41.980619 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:42.241585 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:42.241783 133248269272896 efficientnet_model.py:143] round_filter input=40 output=40\nI1018 01:22:42.500462 133248269272896 efficientnet_model.py:143] round_filter input=40 output=40\nI1018 01:22:42.500715 133248269272896 efficientnet_model.py:143] round_filter input=80 output=80\nI1018 01:22:42.842752 133248269272896 efficientnet_model.py:143] round_filter input=80 output=80\nI1018 01:22:42.842995 133248269272896 efficientnet_model.py:143] round_filter input=112 output=112\nI1018 01:22:43.189844 133248269272896 efficientnet_model.py:143] round_filter input=112 output=112\nI1018 01:22:43.190084 133248269272896 efficientnet_model.py:143] round_filter input=192 output=192\nI1018 01:22:43.608391 133248269272896 efficientnet_model.py:143] round_filter input=192 output=192\nI1018 01:22:43.608608 133248269272896 efficientnet_model.py:143] round_filter input=320 output=320\nI1018 01:22:43.787456 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=1280\nI1018 01:22:43.820025 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:43.886291 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\nI1018 01:22:43.886500 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\nI1018 01:22:43.886617 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\nI1018 01:22:43.888552 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:43.906075 133248269272896 efficientnet_model.py:143] round_filter input=32 output=32\nI1018 01:22:43.906244 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:44.042631 133248269272896 efficientnet_model.py:143] round_filter input=16 output=16\nI1018 01:22:44.042803 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:44.300078 133248269272896 efficientnet_model.py:143] round_filter input=24 output=24\nI1018 01:22:44.300328 133248269272896 efficientnet_model.py:143] round_filter input=40 output=48\nI1018 01:22:44.566468 133248269272896 efficientnet_model.py:143] round_filter input=40 output=48\nI1018 01:22:44.566694 133248269272896 efficientnet_model.py:143] round_filter input=80 output=88\nI1018 01:22:44.916841 133248269272896 efficientnet_model.py:143] round_filter input=80 output=88\nI1018 01:22:44.917068 133248269272896 efficientnet_model.py:143] round_filter input=112 output=120\nI1018 01:22:45.276147 133248269272896 efficientnet_model.py:143] round_filter input=112 output=120\nI1018 01:22:45.276360 133248269272896 efficientnet_model.py:143] round_filter input=192 output=208\nI1018 01:22:45.719636 133248269272896 efficientnet_model.py:143] round_filter input=192 output=208\nI1018 01:22:45.719848 133248269272896 efficientnet_model.py:143] round_filter input=320 output=352\nI1018 01:22:45.898652 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=1408\nI1018 01:22:45.936262 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:46.002633 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\nI1018 01:22:46.002818 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\nI1018 01:22:46.002950 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\nI1018 01:22:46.004863 133248269272896 efficientnet_model.py:143] round_filter input=32 output=40\nI1018 01:22:46.024654 133248269272896 efficientnet_model.py:143] round_filter input=32 output=40\nI1018 01:22:46.024816 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:46.175647 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:46.175832 133248269272896 efficientnet_model.py:143] round_filter input=24 output=32\nI1018 01:22:46.443223 133248269272896 efficientnet_model.py:143] round_filter input=24 output=32\nI1018 01:22:46.443432 133248269272896 efficientnet_model.py:143] round_filter input=40 output=48\nI1018 01:22:46.700784 133248269272896 efficientnet_model.py:143] round_filter input=40 output=48\nI1018 01:22:46.701003 133248269272896 efficientnet_model.py:143] round_filter input=80 output=96\nI1018 01:22:47.126677 133248269272896 efficientnet_model.py:143] round_filter input=80 output=96\nI1018 01:22:47.126909 133248269272896 efficientnet_model.py:143] round_filter input=112 output=136\nI1018 01:22:47.570308 133248269272896 efficientnet_model.py:143] round_filter input=112 output=136\nI1018 01:22:47.570598 133248269272896 efficientnet_model.py:143] round_filter input=192 output=232\nI1018 01:22:48.106807 133248269272896 efficientnet_model.py:143] round_filter input=192 output=232\nI1018 01:22:48.107047 133248269272896 efficientnet_model.py:143] round_filter input=320 output=384\nI1018 01:22:48.299174 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=1536\nI1018 01:22:48.337461 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:48.636223 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\nI1018 01:22:48.636613 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\nI1018 01:22:48.636722 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI1018 01:22:48.638730 133248269272896 efficientnet_model.py:143] round_filter input=32 output=48\nI1018 01:22:48.659095 133248269272896 efficientnet_model.py:143] round_filter input=32 output=48\nI1018 01:22:48.659247 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:48.797369 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:48.797546 133248269272896 efficientnet_model.py:143] round_filter input=24 output=32\nI1018 01:22:49.157480 133248269272896 efficientnet_model.py:143] round_filter input=24 output=32\nI1018 01:22:49.157704 133248269272896 efficientnet_model.py:143] round_filter input=40 output=56\nI1018 01:22:49.520846 133248269272896 efficientnet_model.py:143] round_filter input=40 output=56\nI1018 01:22:49.521065 133248269272896 efficientnet_model.py:143] round_filter input=80 output=112\nI1018 01:22:50.041891 133248269272896 efficientnet_model.py:143] round_filter input=80 output=112\nI1018 01:22:50.042119 133248269272896 efficientnet_model.py:143] round_filter input=112 output=160\nI1018 01:22:50.575917 133248269272896 efficientnet_model.py:143] round_filter input=112 output=160\nI1018 01:22:50.576138 133248269272896 efficientnet_model.py:143] round_filter input=192 output=272\nI1018 01:22:51.287091 133248269272896 efficientnet_model.py:143] round_filter input=192 output=272\nI1018 01:22:51.287302 133248269272896 efficientnet_model.py:143] round_filter input=320 output=448\nI1018 01:22:51.473834 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=1792\nI1018 01:22:51.511403 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:51.590815 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\nI1018 01:22:51.591018 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\nI1018 01:22:51.591105 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI1018 01:22:51.593472 133248269272896 efficientnet_model.py:143] round_filter input=32 output=48\nI1018 01:22:51.610297 133248269272896 efficientnet_model.py:143] round_filter input=32 output=48\nI1018 01:22:51.610447 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:51.812659 133248269272896 efficientnet_model.py:143] round_filter input=16 output=24\nI1018 01:22:51.812854 133248269272896 efficientnet_model.py:143] round_filter input=24 output=40\nI1018 01:22:52.246232 133248269272896 efficientnet_model.py:143] round_filter input=24 output=40\nI1018 01:22:52.246477 133248269272896 efficientnet_model.py:143] round_filter input=40 output=64\nI1018 01:22:52.692073 133248269272896 efficientnet_model.py:143] round_filter input=40 output=64\nI1018 01:22:52.692290 133248269272896 efficientnet_model.py:143] round_filter input=80 output=128\nI1018 01:22:53.306495 133248269272896 efficientnet_model.py:143] round_filter input=80 output=128\nI1018 01:22:53.306723 133248269272896 efficientnet_model.py:143] round_filter input=112 output=176\nI1018 01:22:53.926317 133248269272896 efficientnet_model.py:143] round_filter input=112 output=176\nI1018 01:22:53.926550 133248269272896 efficientnet_model.py:143] round_filter input=192 output=304\nI1018 01:22:54.712641 133248269272896 efficientnet_model.py:143] round_filter input=192 output=304\nI1018 01:22:54.712886 133248269272896 efficientnet_model.py:143] round_filter input=320 output=512\nI1018 01:22:54.979402 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=2048\nI1018 01:22:55.016517 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:55.108478 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\nI1018 01:22:55.108687 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI1018 01:22:55.108791 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI1018 01:22:55.110844 133248269272896 efficientnet_model.py:143] round_filter input=32 output=56\nI1018 01:22:55.130361 133248269272896 efficientnet_model.py:143] round_filter input=32 output=56\nI1018 01:22:55.130498 133248269272896 efficientnet_model.py:143] round_filter input=16 output=32\nI1018 01:22:55.344427 133248269272896 efficientnet_model.py:143] round_filter input=16 output=32\nI1018 01:22:55.344650 133248269272896 efficientnet_model.py:143] round_filter input=24 output=40\nI1018 01:22:55.862093 133248269272896 efficientnet_model.py:143] round_filter input=24 output=40\nI1018 01:22:55.862304 133248269272896 efficientnet_model.py:143] round_filter input=40 output=72\nI1018 01:22:56.662323 133248269272896 efficientnet_model.py:143] round_filter input=40 output=72\nI1018 01:22:56.662537 133248269272896 efficientnet_model.py:143] round_filter input=80 output=144\nI1018 01:22:57.379105 133248269272896 efficientnet_model.py:143] round_filter input=80 output=144\nI1018 01:22:57.379333 133248269272896 efficientnet_model.py:143] round_filter input=112 output=200\nI1018 01:22:58.096911 133248269272896 efficientnet_model.py:143] round_filter input=112 output=200\nI1018 01:22:58.097152 133248269272896 efficientnet_model.py:143] round_filter input=192 output=344\nI1018 01:22:59.070057 133248269272896 efficientnet_model.py:143] round_filter input=192 output=344\nI1018 01:22:59.070334 133248269272896 efficientnet_model.py:143] round_filter input=320 output=576\nI1018 01:22:59.389413 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=2304\nI1018 01:22:59.427226 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:22:59.544751 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\nI1018 01:22:59.544985 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI1018 01:22:59.545101 133248269272896 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI1018 01:22:59.547062 133248269272896 efficientnet_model.py:143] round_filter input=32 output=64\nI1018 01:22:59.566283 133248269272896 efficientnet_model.py:143] round_filter input=32 output=64\nI1018 01:22:59.566437 133248269272896 efficientnet_model.py:143] round_filter input=16 output=32\nI1018 01:22:59.846534 133248269272896 efficientnet_model.py:143] round_filter input=16 output=32\nI1018 01:22:59.846789 133248269272896 efficientnet_model.py:143] round_filter input=24 output=48\nI1018 01:23:00.451050 133248269272896 efficientnet_model.py:143] round_filter input=24 output=48\nI1018 01:23:00.451271 133248269272896 efficientnet_model.py:143] round_filter input=40 output=80\nI1018 01:23:01.043871 133248269272896 efficientnet_model.py:143] round_filter input=40 output=80\nI1018 01:23:01.044116 133248269272896 efficientnet_model.py:143] round_filter input=80 output=160\nI1018 01:23:01.896924 133248269272896 efficientnet_model.py:143] round_filter input=80 output=160\nI1018 01:23:01.897151 133248269272896 efficientnet_model.py:143] round_filter input=112 output=224\nI1018 01:23:02.767984 133248269272896 efficientnet_model.py:143] round_filter input=112 output=224\nI1018 01:23:02.768222 133248269272896 efficientnet_model.py:143] round_filter input=192 output=384\nI1018 01:23:03.879296 133248269272896 efficientnet_model.py:143] round_filter input=192 output=384\nI1018 01:23:03.879535 133248269272896 efficientnet_model.py:143] round_filter input=320 output=640\nI1018 01:23:04.237394 133248269272896 efficientnet_model.py:143] round_filter input=1280 output=2560\nI1018 01:23:04.275810 133248269272896 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI1018 01:23:04.665531 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.81s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\nI1018 01:23:04.690283 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\nI1018 01:23:04.691960 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\nI1018 01:23:04.692461 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\nI1018 01:23:04.693814 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n[ RUN      ] ModelBuilderTF2Test.test_session\n[  SKIPPED ] ModelBuilderTF2Test.test_session\n[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\nI1018 01:23:04.695156 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\nI1018 01:23:04.695594 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\nI1018 01:23:04.696548 133248269272896 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n----------------------------------------------------------------------\nRan 24 tests in 32.315s\n\nOK (skipped=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wget","metadata":{"id":"aaLKjpJXIhZ0","outputId":"cbe506ca-b067-4ae7-ea9d-296a3610de5d","execution":{"iopub.status.busy":"2023-10-18T01:23:06.921402Z","iopub.execute_input":"2023-10-18T01:23:06.921689Z","iopub.status.idle":"2023-10-18T01:23:16.788137Z","shell.execute_reply.started":"2023-10-18T01:23:06.921663Z","shell.execute_reply":"2023-10-18T01:23:16.787163Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting wget\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=84f4c77bfc5beb661767748ec4c9374089ab92226bbc41008a6a7b4604d13c52\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\nSuccessfully built wget\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config\n!mv ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config /kaggle/working/ssd_resnet101.config","metadata":{"id":"ypYQ1Pk1Inng","outputId":"042481a4-da15-45da-fd7b-70975d9ea2a3","execution":{"iopub.status.busy":"2023-10-18T01:23:16.789426Z","iopub.execute_input":"2023-10-18T01:23:16.789684Z","iopub.status.idle":"2023-10-18T01:23:18.936958Z","shell.execute_reply.started":"2023-10-18T01:23:16.789659Z","shell.execute_reply":"2023-10-18T01:23:18.935921Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"--2023-10-18 01:23:17--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4531 (4.4K) [text/plain]\nSaving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config’\n\nssd_resnet101_v1_fp 100%[===================>]   4.42K  --.-KB/s    in 0s      \n\n2023-10-18 01:23:17 (35.0 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config’ saved [4531/4531]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"num_classes = 12\nbatch_size = 4\nnum_steps = 20000\nnum_eval_steps = 1000\n\ntrain_record_path = '/kaggle/input/tfrecord/train.tfrecord'\ntest_record_path = '/kaggle/input/tfrecord/test.tfrecord'\nmodel_dir = '/kaggle/working/training/'\nlabelmap_path = '/kaggle/input/labelmap/labelmap.pbtxt'\n\npipeline_config_path = '/kaggle/working/ssd_resnet101.config'\nfine_tune_checkpoint = '/kaggle/working/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'","metadata":{"execution":{"iopub.status.busy":"2023-10-18T01:23:18.939831Z","iopub.execute_input":"2023-10-18T01:23:18.940083Z","iopub.status.idle":"2023-10-18T01:23:18.944973Z","shell.execute_reply.started":"2023-10-18T01:23:18.940060Z","shell.execute_reply":"2023-10-18T01:23:18.944351Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import re\n\nwith open(pipeline_config_path) as f:\n    config = f.read()\n\nwith open(pipeline_config_path, 'w') as f:\n\n    # Set labelmap path\n    config = re.sub('label_map_path: \".*?\"',\n                  'label_map_path: \"{}\"'.format(labelmap_path), config)\n\n    # Set fine_tune_checkpoint path\n    config = re.sub('fine_tune_checkpoint: \".*?\"',\n                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n\n    # Set fine_tune_checkpoint typr\n    config = re.sub('fine_tune_checkpoint_type: \".*?\"',\n                  'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n\n    # Set train tf-record file path\n    config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n                  'input_path: \"{}\"'.format(train_record_path), config)\n\n    # Set test tf-record file path\n    config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n                  'input_path: \"{}\"'.format(test_record_path), config)\n\n    # Set number of classes.\n    config = re.sub('num_classes: [0-9]+',\n                  'num_classes: {}'.format(num_classes), config)\n\n    # Set batch size\n    config = re.sub('batch_size: [0-9]+',\n                  'batch_size: {}'.format(batch_size), config)\n\n    # Set training steps\n    config = re.sub('num_steps: [0-9]+',\n                  'num_steps: {}'.format(num_steps), config)\n    \n    # Set learning rate\n   # config = re.sub('learning_rate_base: [.0-9]+',\n    #              'learning_rate_base: {}'.format(learning_rate), config)\n\n    f.write(config)","metadata":{"id":"Iho0suoMKRn0","execution":{"iopub.status.busy":"2023-10-18T01:23:18.945846Z","iopub.execute_input":"2023-10-18T01:23:18.946063Z","iopub.status.idle":"2023-10-18T01:23:18.959419Z","shell.execute_reply.started":"2023-10-18T01:23:18.946045Z","shell.execute_reply":"2023-10-18T01:23:18.958825Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import re\n\n# Hapus seluruh blok konfigurasi optimizer momentum\nconfig = re.sub(r'optimizer\\s*{[^}]*}', '', config)\n\n    # Pengaturan optimizer Adam yang akan digunakan\nrms_prop_optimizer_config = \"\"\"\n    optimizer {\n      rms_prop_optimizer: {\n        learning_rate: {\n          cosine_decay_learning_rate {\n            learning_rate: 0.001  # Sesuaikan dengan kebutuhan Anda\n          }\n        }\n      }\n      use_moving_average: false\n    }\n    \"\"\"\n\n    # Gabungkan pengaturan optimizer Adam dengan konfigurasi yang ada\nconfig += rms_prop_optimizer_config\n\nprint(config)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T01:23:18.960552Z","iopub.execute_input":"2023-10-18T01:23:18.960749Z","iopub.status.idle":"2023-10-18T01:23:18.976986Z","shell.execute_reply.started":"2023-10-18T01:23:18.960732Z","shell.execute_reply":"2023-10-18T01:23:18.976302Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"# SSD with Resnet 101 v1 FPN feature extractor, shared box predictor and focal\n# loss (a.k.a Retinanet).\n# See Lin et al, https://arxiv.org/abs/1708.02002\n# Trained on COCO, initialized from Imagenet classification checkpoint\n# Train on TPU-8\n#\n# Achieves 35.4 mAP on COCO17 Val\n\nmodel {\n  ssd {\n    inplace_batchnorm_update: true\n    freeze_batchnorm: false\n    num_classes: 12\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n        use_matmul_gather: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    encode_background_as_zeros: true\n    anchor_generator {\n      multiscale_anchor_generator {\n        min_level: 3\n        max_level: 7\n        anchor_scale: 4.0\n        aspect_ratios: [1.0, 2.0, 0.5]\n        scales_per_octave: 2\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 640\n        width: 640\n      }\n    }\n    box_predictor {\n      weight_shared_convolutional_box_predictor {\n        depth: 256\n        class_prediction_bias_init: -4.6\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.0004\n            }\n          }\n          initializer {\n            random_normal_initializer {\n              stddev: 0.01\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            scale: true,\n            decay: 0.997,\n            epsilon: 0.001,\n          }\n        }\n        num_layers_before_predictor: 4\n        kernel_size: 3\n      }\n    }\n    feature_extractor {\n      type: 'ssd_resnet101_v1_fpn_keras'\n      fpn {\n        min_level: 3\n        max_level: 7\n      }\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.0004\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            stddev: 0.03\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          scale: true,\n          decay: 0.997,\n          epsilon: 0.001,\n        }\n      }\n      override_base_feature_extractor_hyperparams: true\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid_focal {\n          alpha: 0.25\n          gamma: 2.0\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    normalize_loss_by_num_matches: true\n    normalize_loc_loss_by_codesize: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config: {\n  fine_tune_checkpoint_version: V2\n  fine_tune_checkpoint: \"/kaggle/working/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n  fine_tune_checkpoint_type: \"detection\"\n  batch_size: 4\n  sync_replicas: true\n  startup_delay_steps: 0\n  replicas_to_aggregate: 8\n  use_bfloat16: true\n  num_steps: 20000\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    random_crop_image {\n      min_object_covered: 0.0\n      min_aspect_ratio: 0.75\n      max_aspect_ratio: 3.0\n      min_area: 0.75\n      max_area: 1.0\n      overlap_thresh: 0.0\n    }\n  }\n  \n      }\n      momentum_optimizer_value: 0.9\n    }\n    use_moving_average: false\n  }\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n}\n\ntrain_input_reader: {\n  label_map_path: \"/kaggle/input/labelmap/labelmap.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"/kaggle/input/tfrecord/train.tfrecord\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n}\n\neval_input_reader: {\n  label_map_path: \"/kaggle/input/labelmap/labelmap.pbtxt\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \"/kaggle/input/tfrecord/test.tfrecord\"\n  }\n}\n\n    optimizer {\n      rms_prop_optimizer: {\n        learning_rate: {\n          cosine_decay_learning_rate {\n            learning_rate: 0.001  # Sesuaikan dengan kebutuhan Anda\n          }\n        }\n      }\n      use_moving_average: false\n    }\n    \n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    #--checkpoint_every_n=100 \\\n    --num_eval_steps={num_eval_steps}","metadata":{"id":"4Uv2-zruJ1u6","outputId":"23526dbd-ad30-4efe-857e-a32fba700aad","execution":{"iopub.status.busy":"2023-10-18T01:23:18.978055Z","iopub.execute_input":"2023-10-18T01:23:18.978270Z","iopub.status.idle":"2023-10-18T03:58:45.687888Z","shell.execute_reply.started":"2023-10-18T01:23:18.978252Z","shell.execute_reply":"2023-10-18T03:58:45.686980Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nI1018 01:23:26.461576 140662142089024 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI1018 01:23:27.154825 140662142089024 config_util.py:552] Maybe overwriting train_steps: 20000\nI1018 01:23:27.155072 140662142089024 config_util.py:552] Maybe overwriting use_bfloat16: False\nW1018 01:23:27.188851 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI1018 01:23:27.210133 140662142089024 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/input/tfrecord/train.tfrecord']\nI1018 01:23:27.215061 140662142089024 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/input/tfrecord/train.tfrecord']\nI1018 01:23:27.215207 140662142089024 dataset_builder.py:80] Number of filenames to read: 1\nW1018 01:23:27.215301 140662142089024 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW1018 01:23:27.221918 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW1018 01:23:27.240070 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW1018 01:23:33.293673 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW1018 01:23:35.892554 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nW1018 01:23:37.428298 140662142089024 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/opt/conda/lib/python3.10/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn(\nI1018 01:23:46.965843 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:23:54.836655 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:23:58.475984 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:01.770290 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:18.815480 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.819816 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.821047 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.822069 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.824916 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.825865 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.826876 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.827859 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.830764 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI1018 01:24:18.831782 140662142089024 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nW1018 01:24:21.076044 140656236287552 deprecation.py:569] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\nI1018 01:24:23.125472 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:29.204283 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:33.027344 140662142089024 cross_device_ops.py:1152] Collective all_reduce tensors: 422 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI1018 01:24:41.096557 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:46.367428 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:24:50.473730 140662142089024 cross_device_ops.py:1152] Collective all_reduce tensors: 422 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI1018 01:24:57.048245 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:25:02.561199 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:25:06.357212 140662142089024 cross_device_ops.py:1152] Collective all_reduce tensors: 422 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI1018 01:25:14.896622 140655974151744 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:25:20.159812 140656236287552 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 01:25:23.717648 140662142089024 cross_device_ops.py:1152] Collective all_reduce tensors: 422 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nI1018 01:26:39.875128 140662142089024 model_lib_v2.py:705] Step 100 per-step time 1.391s\nI1018 01:26:39.875491 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 2.5221329,\n 'Loss/localization_loss': 0.45766518,\n 'Loss/regularization_loss': 1.915822,\n 'Loss/total_loss': 4.8956203,\n 'learning_rate': 0.014666351}\nI1018 01:27:24.393649 140662142089024 model_lib_v2.py:705] Step 200 per-step time 0.445s\nI1018 01:27:24.393968 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 1.6575508,\n 'Loss/localization_loss': 0.32535207,\n 'Loss/regularization_loss': 2.987975,\n 'Loss/total_loss': 4.9708776,\n 'learning_rate': 0.0159997}\nI1018 01:28:09.809001 140662142089024 model_lib_v2.py:705] Step 300 per-step time 0.454s\nI1018 01:28:09.809356 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 1.1136386,\n 'Loss/localization_loss': 0.4733181,\n 'Loss/regularization_loss': 3.0215547,\n 'Loss/total_loss': 4.608511,\n 'learning_rate': 0.01733305}\nI1018 01:28:55.343407 140662142089024 model_lib_v2.py:705] Step 400 per-step time 0.455s\nI1018 01:28:55.343828 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.80418193,\n 'Loss/localization_loss': 0.52627033,\n 'Loss/regularization_loss': 2.9943469,\n 'Loss/total_loss': 4.324799,\n 'learning_rate': 0.0186664}\nI1018 01:29:40.830051 140662142089024 model_lib_v2.py:705] Step 500 per-step time 0.455s\nI1018 01:29:40.830464 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.65759546,\n 'Loss/localization_loss': 0.46717483,\n 'Loss/regularization_loss': 2.949643,\n 'Loss/total_loss': 4.0744133,\n 'learning_rate': 0.01999975}\nI1018 01:30:26.439794 140662142089024 model_lib_v2.py:705] Step 600 per-step time 0.456s\nI1018 01:30:26.440338 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.674209,\n 'Loss/localization_loss': 0.30310205,\n 'Loss/regularization_loss': 2.909942,\n 'Loss/total_loss': 3.8872528,\n 'learning_rate': 0.0213331}\nI1018 01:31:11.950493 140662142089024 model_lib_v2.py:705] Step 700 per-step time 0.455s\nI1018 01:31:11.950834 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6816361,\n 'Loss/localization_loss': 0.49329406,\n 'Loss/regularization_loss': 2.861675,\n 'Loss/total_loss': 4.036605,\n 'learning_rate': 0.02266645}\nI1018 01:31:57.445729 140662142089024 model_lib_v2.py:705] Step 800 per-step time 0.455s\nI1018 01:31:57.446079 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6071017,\n 'Loss/localization_loss': 0.46188444,\n 'Loss/regularization_loss': 2.8099027,\n 'Loss/total_loss': 3.8788888,\n 'learning_rate': 0.023999799}\nI1018 01:32:42.994244 140662142089024 model_lib_v2.py:705] Step 900 per-step time 0.455s\nI1018 01:32:42.994571 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.63619745,\n 'Loss/localization_loss': 0.48323536,\n 'Loss/regularization_loss': 2.756284,\n 'Loss/total_loss': 3.875717,\n 'learning_rate': 0.025333151}\nI1018 01:33:28.514108 140662142089024 model_lib_v2.py:705] Step 1000 per-step time 0.455s\nI1018 01:33:28.514428 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.71821785,\n 'Loss/localization_loss': 0.3956025,\n 'Loss/regularization_loss': 2.7009468,\n 'Loss/total_loss': 3.8147674,\n 'learning_rate': 0.0266665}\nI1018 01:34:17.894989 140662142089024 model_lib_v2.py:705] Step 1100 per-step time 0.494s\nI1018 01:34:17.895361 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.78804845,\n 'Loss/localization_loss': 0.43918127,\n 'Loss/regularization_loss': 2.6451774,\n 'Loss/total_loss': 3.872407,\n 'learning_rate': 0.02799985}\nI1018 01:35:03.269995 140662142089024 model_lib_v2.py:705] Step 1200 per-step time 0.454s\nI1018 01:35:03.270313 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5388742,\n 'Loss/localization_loss': 0.27634588,\n 'Loss/regularization_loss': 2.586664,\n 'Loss/total_loss': 3.401884,\n 'learning_rate': 0.0293332}\nI1018 01:35:48.686222 140662142089024 model_lib_v2.py:705] Step 1300 per-step time 0.454s\nI1018 01:35:48.686591 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4598659,\n 'Loss/localization_loss': 0.3080601,\n 'Loss/regularization_loss': 2.5265696,\n 'Loss/total_loss': 3.2944956,\n 'learning_rate': 0.03066655}\nI1018 01:36:34.195686 140662142089024 model_lib_v2.py:705] Step 1400 per-step time 0.455s\nI1018 01:36:34.196018 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6265,\n 'Loss/localization_loss': 0.27883282,\n 'Loss/regularization_loss': 2.4657598,\n 'Loss/total_loss': 3.3710926,\n 'learning_rate': 0.0319999}\nI1018 01:37:19.711518 140662142089024 model_lib_v2.py:705] Step 1500 per-step time 0.455s\nI1018 01:37:19.711842 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.7810875,\n 'Loss/localization_loss': 0.46823776,\n 'Loss/regularization_loss': 2.404543,\n 'Loss/total_loss': 3.6538682,\n 'learning_rate': 0.03333325}\nI1018 01:38:05.204570 140662142089024 model_lib_v2.py:705] Step 1600 per-step time 0.455s\nI1018 01:38:05.205095 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.48807365,\n 'Loss/localization_loss': 0.21203251,\n 'Loss/regularization_loss': 2.3425982,\n 'Loss/total_loss': 3.0427043,\n 'learning_rate': 0.034666598}\nI1018 01:38:50.734988 140662142089024 model_lib_v2.py:705] Step 1700 per-step time 0.455s\nI1018 01:38:50.735321 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.533217,\n 'Loss/localization_loss': 0.2509245,\n 'Loss/regularization_loss': 2.2793238,\n 'Loss/total_loss': 3.0634654,\n 'learning_rate': 0.03599995}\nI1018 01:39:36.158914 140662142089024 model_lib_v2.py:705] Step 1800 per-step time 0.454s\nI1018 01:39:36.159255 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49530283,\n 'Loss/localization_loss': 0.15843026,\n 'Loss/regularization_loss': 2.215786,\n 'Loss/total_loss': 2.8695192,\n 'learning_rate': 0.037333302}\nI1018 01:40:21.708995 140662142089024 model_lib_v2.py:705] Step 1900 per-step time 0.456s\nI1018 01:40:21.709461 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6014142,\n 'Loss/localization_loss': 0.3709188,\n 'Loss/regularization_loss': 2.1516492,\n 'Loss/total_loss': 3.1239822,\n 'learning_rate': 0.03866665}\nI1018 01:41:07.173800 140662142089024 model_lib_v2.py:705] Step 2000 per-step time 0.455s\nI1018 01:41:07.174149 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.45209026,\n 'Loss/localization_loss': 0.17442344,\n 'Loss/regularization_loss': 2.0873895,\n 'Loss/total_loss': 2.7139032,\n 'learning_rate': 0.04}\nI1018 01:41:55.621748 140662142089024 model_lib_v2.py:705] Step 2100 per-step time 0.484s\nI1018 01:41:55.622177 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.50042504,\n 'Loss/localization_loss': 0.26595008,\n 'Loss/regularization_loss': 2.0238013,\n 'Loss/total_loss': 2.7901764,\n 'learning_rate': 0.039998136}\nI1018 01:42:41.134700 140662142089024 model_lib_v2.py:705] Step 2200 per-step time 0.455s\nI1018 01:42:41.135100 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5477149,\n 'Loss/localization_loss': 0.40481204,\n 'Loss/regularization_loss': 1.9631218,\n 'Loss/total_loss': 2.9156487,\n 'learning_rate': 0.039992537}\nI1018 01:43:26.718076 140662142089024 model_lib_v2.py:705] Step 2300 per-step time 0.456s\nI1018 01:43:26.718418 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6234122,\n 'Loss/localization_loss': 0.32433033,\n 'Loss/regularization_loss': 1.9046088,\n 'Loss/total_loss': 2.8523512,\n 'learning_rate': 0.03998321}\nI1018 01:44:12.190694 140662142089024 model_lib_v2.py:705] Step 2400 per-step time 0.455s\nI1018 01:44:12.191059 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4510943,\n 'Loss/localization_loss': 0.27632225,\n 'Loss/regularization_loss': 1.846928,\n 'Loss/total_loss': 2.5743446,\n 'learning_rate': 0.039970152}\nI1018 01:44:57.824640 140662142089024 model_lib_v2.py:705] Step 2500 per-step time 0.456s\nI1018 01:44:57.824967 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.41448036,\n 'Loss/localization_loss': 0.12206489,\n 'Loss/regularization_loss': 1.7908221,\n 'Loss/total_loss': 2.3273673,\n 'learning_rate': 0.039953373}\nI1018 01:45:43.264565 140662142089024 model_lib_v2.py:705] Step 2600 per-step time 0.454s\nI1018 01:45:43.264889 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.55172646,\n 'Loss/localization_loss': 0.3353187,\n 'Loss/regularization_loss': 1.7363249,\n 'Loss/total_loss': 2.62337,\n 'learning_rate': 0.03993287}\nI1018 01:46:28.769457 140662142089024 model_lib_v2.py:705] Step 2700 per-step time 0.455s\nI1018 01:46:28.769887 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49496648,\n 'Loss/localization_loss': 0.20942982,\n 'Loss/regularization_loss': 1.6834444,\n 'Loss/total_loss': 2.3878407,\n 'learning_rate': 0.039908648}\nI1018 01:47:14.203812 140662142089024 model_lib_v2.py:705] Step 2800 per-step time 0.454s\nI1018 01:47:14.204144 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5114744,\n 'Loss/localization_loss': 0.28090328,\n 'Loss/regularization_loss': 1.632472,\n 'Loss/total_loss': 2.4248495,\n 'learning_rate': 0.039880715}\nI1018 01:47:59.765766 140662142089024 model_lib_v2.py:705] Step 2900 per-step time 0.456s\nI1018 01:47:59.766134 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49375165,\n 'Loss/localization_loss': 0.316964,\n 'Loss/regularization_loss': 1.5834063,\n 'Loss/total_loss': 2.3941221,\n 'learning_rate': 0.039849065}\nI1018 01:48:45.208279 140662142089024 model_lib_v2.py:705] Step 3000 per-step time 0.454s\nI1018 01:48:45.208637 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5144853,\n 'Loss/localization_loss': 0.1819387,\n 'Loss/regularization_loss': 1.5355307,\n 'Loss/total_loss': 2.2319546,\n 'learning_rate': 0.03981372}\nI1018 01:49:33.521954 140662142089024 model_lib_v2.py:705] Step 3100 per-step time 0.483s\nI1018 01:49:33.522283 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.57598907,\n 'Loss/localization_loss': 0.17269777,\n 'Loss/regularization_loss': 1.4895718,\n 'Loss/total_loss': 2.2382586,\n 'learning_rate': 0.03977467}\nI1018 01:50:19.211261 140662142089024 model_lib_v2.py:705] Step 3200 per-step time 0.457s\nI1018 01:50:19.211606 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.36047554,\n 'Loss/localization_loss': 0.07788172,\n 'Loss/regularization_loss': 1.4448229,\n 'Loss/total_loss': 1.8831801,\n 'learning_rate': 0.03973194}\nI1018 01:51:04.700000 140662142089024 model_lib_v2.py:705] Step 3300 per-step time 0.455s\nI1018 01:51:04.700320 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5514959,\n 'Loss/localization_loss': 0.25295672,\n 'Loss/regularization_loss': 1.4036412,\n 'Loss/total_loss': 2.208094,\n 'learning_rate': 0.03968552}\nI1018 01:51:50.412140 140662142089024 model_lib_v2.py:705] Step 3400 per-step time 0.457s\nI1018 01:51:50.412491 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.57830375,\n 'Loss/localization_loss': 0.3565092,\n 'Loss/regularization_loss': 1.3652029,\n 'Loss/total_loss': 2.300016,\n 'learning_rate': 0.039635435}\nI1018 01:52:36.041280 140662142089024 model_lib_v2.py:705] Step 3500 per-step time 0.456s\nI1018 01:52:36.041648 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.58163345,\n 'Loss/localization_loss': 0.31995785,\n 'Loss/regularization_loss': 1.3262718,\n 'Loss/total_loss': 2.227863,\n 'learning_rate': 0.03958168}\nI1018 01:53:21.663266 140662142089024 model_lib_v2.py:705] Step 3600 per-step time 0.456s\nI1018 01:53:21.663713 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.59908545,\n 'Loss/localization_loss': 0.38561714,\n 'Loss/regularization_loss': 1.306609,\n 'Loss/total_loss': 2.2913115,\n 'learning_rate': 0.039524276}\nI1018 01:54:07.494476 140662142089024 model_lib_v2.py:705] Step 3700 per-step time 0.458s\nI1018 01:54:07.494793 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.45702296,\n 'Loss/localization_loss': 0.30248705,\n 'Loss/regularization_loss': 1.2700073,\n 'Loss/total_loss': 2.0295172,\n 'learning_rate': 0.03946323}\nI1018 01:54:53.317094 140662142089024 model_lib_v2.py:705] Step 3800 per-step time 0.458s\nI1018 01:54:53.317399 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.47641075,\n 'Loss/localization_loss': 0.29767787,\n 'Loss/regularization_loss': 1.2346102,\n 'Loss/total_loss': 2.008699,\n 'learning_rate': 0.039398547}\nI1018 01:55:39.028872 140662142089024 model_lib_v2.py:705] Step 3900 per-step time 0.457s\nI1018 01:55:39.029237 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.40353164,\n 'Loss/localization_loss': 0.2044113,\n 'Loss/regularization_loss': 1.199168,\n 'Loss/total_loss': 1.8071109,\n 'learning_rate': 0.039330248}\nI1018 01:56:24.737604 140662142089024 model_lib_v2.py:705] Step 4000 per-step time 0.457s\nI1018 01:56:24.737952 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.52597845,\n 'Loss/localization_loss': 0.26936156,\n 'Loss/regularization_loss': 1.1647147,\n 'Loss/total_loss': 1.9600548,\n 'learning_rate': 0.039258346}\nI1018 01:57:13.471390 140662142089024 model_lib_v2.py:705] Step 4100 per-step time 0.487s\nI1018 01:57:13.471728 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49950552,\n 'Loss/localization_loss': 0.21350312,\n 'Loss/regularization_loss': 1.1315483,\n 'Loss/total_loss': 1.8445568,\n 'learning_rate': 0.03918285}\nI1018 01:57:59.072389 140662142089024 model_lib_v2.py:705] Step 4200 per-step time 0.456s\nI1018 01:57:59.072724 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5478539,\n 'Loss/localization_loss': 0.32551816,\n 'Loss/regularization_loss': 1.1037865,\n 'Loss/total_loss': 1.9771585,\n 'learning_rate': 0.03910377}\nI1018 01:58:44.717955 140662142089024 model_lib_v2.py:705] Step 4300 per-step time 0.456s\nI1018 01:58:44.718284 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.47361362,\n 'Loss/localization_loss': 0.20824131,\n 'Loss/regularization_loss': 1.0726882,\n 'Loss/total_loss': 1.7545432,\n 'learning_rate': 0.039021127}\nI1018 01:59:30.419260 140662142089024 model_lib_v2.py:705] Step 4400 per-step time 0.457s\nI1018 01:59:30.419614 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.44101828,\n 'Loss/localization_loss': 0.13863023,\n 'Loss/regularization_loss': 1.0423625,\n 'Loss/total_loss': 1.622011,\n 'learning_rate': 0.03893494}\nI1018 02:00:16.023748 140662142089024 model_lib_v2.py:705] Step 4500 per-step time 0.456s\nI1018 02:00:16.024085 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.6271287,\n 'Loss/localization_loss': 0.39974004,\n 'Loss/regularization_loss': 1.0131004,\n 'Loss/total_loss': 2.039969,\n 'learning_rate': 0.03884522}\nI1018 02:01:01.554067 140662142089024 model_lib_v2.py:705] Step 4600 per-step time 0.455s\nI1018 02:01:01.554404 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4229163,\n 'Loss/localization_loss': 0.10115006,\n 'Loss/regularization_loss': 0.9845963,\n 'Loss/total_loss': 1.5086627,\n 'learning_rate': 0.03875198}\nI1018 02:01:47.190232 140662142089024 model_lib_v2.py:705] Step 4700 per-step time 0.456s\nI1018 02:01:47.190566 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4641567,\n 'Loss/localization_loss': 0.114471026,\n 'Loss/regularization_loss': 0.9570655,\n 'Loss/total_loss': 1.5356933,\n 'learning_rate': 0.038655244}\nI1018 02:02:32.815325 140662142089024 model_lib_v2.py:705] Step 4800 per-step time 0.456s\nI1018 02:02:32.815650 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5778541,\n 'Loss/localization_loss': 0.32550806,\n 'Loss/regularization_loss': 0.93059707,\n 'Loss/total_loss': 1.8339592,\n 'learning_rate': 0.038555026}\nI1018 02:03:18.448749 140662142089024 model_lib_v2.py:705] Step 4900 per-step time 0.456s\nI1018 02:03:18.449262 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.43565446,\n 'Loss/localization_loss': 0.28867725,\n 'Loss/regularization_loss': 0.9049042,\n 'Loss/total_loss': 1.629236,\n 'learning_rate': 0.038451348}\nI1018 02:04:03.981910 140662142089024 model_lib_v2.py:705] Step 5000 per-step time 0.455s\nI1018 02:04:03.982267 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.41613483,\n 'Loss/localization_loss': 0.2072747,\n 'Loss/regularization_loss': 0.8801928,\n 'Loss/total_loss': 1.5036024,\n 'learning_rate': 0.038344227}\nI1018 02:04:52.457283 140662142089024 model_lib_v2.py:705] Step 5100 per-step time 0.485s\nI1018 02:04:52.457608 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.44655102,\n 'Loss/localization_loss': 0.13836646,\n 'Loss/regularization_loss': 0.8562504,\n 'Loss/total_loss': 1.4411678,\n 'learning_rate': 0.03823368}\nI1018 02:05:38.021905 140662142089024 model_lib_v2.py:705] Step 5200 per-step time 0.456s\nI1018 02:05:38.022357 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4552288,\n 'Loss/localization_loss': 0.2527633,\n 'Loss/regularization_loss': 0.83314,\n 'Loss/total_loss': 1.5411321,\n 'learning_rate': 0.038119733}\nI1018 02:06:23.687361 140662142089024 model_lib_v2.py:705] Step 5300 per-step time 0.457s\nI1018 02:06:23.687685 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.60818505,\n 'Loss/localization_loss': 0.33649212,\n 'Loss/regularization_loss': 0.81136346,\n 'Loss/total_loss': 1.7560407,\n 'learning_rate': 0.03800241}\nI1018 02:07:09.318984 140662142089024 model_lib_v2.py:705] Step 5400 per-step time 0.456s\nI1018 02:07:09.319328 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.41934106,\n 'Loss/localization_loss': 0.11087476,\n 'Loss/regularization_loss': 0.79043233,\n 'Loss/total_loss': 1.3206482,\n 'learning_rate': 0.037881725}\nI1018 02:07:54.989917 140662142089024 model_lib_v2.py:705] Step 5500 per-step time 0.457s\nI1018 02:07:54.990278 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4815545,\n 'Loss/localization_loss': 0.23867203,\n 'Loss/regularization_loss': 0.77032274,\n 'Loss/total_loss': 1.4905493,\n 'learning_rate': 0.037757702}\nI1018 02:08:40.431913 140662142089024 model_lib_v2.py:705] Step 5600 per-step time 0.454s\nI1018 02:08:40.432251 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.47959635,\n 'Loss/localization_loss': 0.36700553,\n 'Loss/regularization_loss': 0.7519865,\n 'Loss/total_loss': 1.5985885,\n 'learning_rate': 0.03763037}\nI1018 02:09:25.774164 140662142089024 model_lib_v2.py:705] Step 5700 per-step time 0.453s\nI1018 02:09:25.774552 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49722898,\n 'Loss/localization_loss': 0.24136527,\n 'Loss/regularization_loss': 0.7334405,\n 'Loss/total_loss': 1.4720347,\n 'learning_rate': 0.03749975}\nI1018 02:10:11.298474 140662142089024 model_lib_v2.py:705] Step 5800 per-step time 0.455s\nI1018 02:10:11.298819 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.40462655,\n 'Loss/localization_loss': 0.08308832,\n 'Loss/regularization_loss': 0.71486926,\n 'Loss/total_loss': 1.2025841,\n 'learning_rate': 0.037365858}\nI1018 02:10:56.647170 140662142089024 model_lib_v2.py:705] Step 5900 per-step time 0.453s\nI1018 02:10:56.647498 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3306461,\n 'Loss/localization_loss': 0.063182056,\n 'Loss/regularization_loss': 0.6998178,\n 'Loss/total_loss': 1.0936459,\n 'learning_rate': 0.03722873}\nI1018 02:11:42.044587 140662142089024 model_lib_v2.py:705] Step 6000 per-step time 0.454s\nI1018 02:11:42.044893 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5503832,\n 'Loss/localization_loss': 0.28883263,\n 'Loss/regularization_loss': 0.6836216,\n 'Loss/total_loss': 1.5228374,\n 'learning_rate': 0.037088387}\nI1018 02:12:30.382563 140662142089024 model_lib_v2.py:705] Step 6100 per-step time 0.483s\nI1018 02:12:30.382915 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.50925416,\n 'Loss/localization_loss': 0.12097266,\n 'Loss/regularization_loss': 0.6676817,\n 'Loss/total_loss': 1.2979085,\n 'learning_rate': 0.036944855}\nI1018 02:13:15.825603 140662142089024 model_lib_v2.py:705] Step 6200 per-step time 0.454s\nI1018 02:13:15.825907 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5654157,\n 'Loss/localization_loss': 0.23669887,\n 'Loss/regularization_loss': 0.65104246,\n 'Loss/total_loss': 1.453157,\n 'learning_rate': 0.036798168}\nI1018 02:14:01.232831 140662142089024 model_lib_v2.py:705] Step 6300 per-step time 0.454s\nI1018 02:14:01.233182 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4847741,\n 'Loss/localization_loss': 0.12613277,\n 'Loss/regularization_loss': 0.63561934,\n 'Loss/total_loss': 1.2465262,\n 'learning_rate': 0.03664834}\nI1018 02:14:46.921349 140662142089024 model_lib_v2.py:705] Step 6400 per-step time 0.457s\nI1018 02:14:46.921682 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3731477,\n 'Loss/localization_loss': 0.06942107,\n 'Loss/regularization_loss': 0.62183976,\n 'Loss/total_loss': 1.0644085,\n 'learning_rate': 0.03649541}\nI1018 02:15:32.341415 140662142089024 model_lib_v2.py:705] Step 6500 per-step time 0.454s\nI1018 02:15:32.341737 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4039619,\n 'Loss/localization_loss': 0.04293132,\n 'Loss/regularization_loss': 0.6067964,\n 'Loss/total_loss': 1.0536896,\n 'learning_rate': 0.0363394}\nI1018 02:16:17.719064 140662142089024 model_lib_v2.py:705] Step 6600 per-step time 0.454s\nI1018 02:16:17.719390 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.55427694,\n 'Loss/localization_loss': 0.19091533,\n 'Loss/regularization_loss': 0.5929256,\n 'Loss/total_loss': 1.338118,\n 'learning_rate': 0.03618034}\nI1018 02:17:03.030150 140662142089024 model_lib_v2.py:705] Step 6700 per-step time 0.453s\nI1018 02:17:03.030467 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4860398,\n 'Loss/localization_loss': 0.26656026,\n 'Loss/regularization_loss': 0.5794959,\n 'Loss/total_loss': 1.3320959,\n 'learning_rate': 0.03601826}\nI1018 02:17:48.539074 140662142089024 model_lib_v2.py:705] Step 6800 per-step time 0.455s\nI1018 02:17:48.539440 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5064161,\n 'Loss/localization_loss': 0.07671787,\n 'Loss/regularization_loss': 0.5775453,\n 'Loss/total_loss': 1.1606792,\n 'learning_rate': 0.035853196}\nI1018 02:18:33.871078 140662142089024 model_lib_v2.py:705] Step 6900 per-step time 0.453s\nI1018 02:18:33.871419 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.48626834,\n 'Loss/localization_loss': 0.22942793,\n 'Loss/regularization_loss': 0.564353,\n 'Loss/total_loss': 1.2800493,\n 'learning_rate': 0.035685178}\nI1018 02:19:19.222572 140662142089024 model_lib_v2.py:705] Step 7000 per-step time 0.454s\nI1018 02:19:19.222887 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.39176038,\n 'Loss/localization_loss': 0.16484058,\n 'Loss/regularization_loss': 0.551406,\n 'Loss/total_loss': 1.108007,\n 'learning_rate': 0.035514224}\nI1018 02:20:07.516767 140662142089024 model_lib_v2.py:705] Step 7100 per-step time 0.483s\nI1018 02:20:07.517208 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4298484,\n 'Loss/localization_loss': 0.19103009,\n 'Loss/regularization_loss': 0.53901887,\n 'Loss/total_loss': 1.1598973,\n 'learning_rate': 0.035340384}\nI1018 02:20:53.143435 140662142089024 model_lib_v2.py:705] Step 7200 per-step time 0.456s\nI1018 02:20:53.143775 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.39513463,\n 'Loss/localization_loss': 0.27548888,\n 'Loss/regularization_loss': 0.52675456,\n 'Loss/total_loss': 1.1973782,\n 'learning_rate': 0.035163675}\nI1018 02:21:38.869250 140662142089024 model_lib_v2.py:705] Step 7300 per-step time 0.457s\nI1018 02:21:38.869625 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3263439,\n 'Loss/localization_loss': 0.106794685,\n 'Loss/regularization_loss': 0.51485276,\n 'Loss/total_loss': 0.9479913,\n 'learning_rate': 0.034984138}\nI1018 02:22:24.388232 140662142089024 model_lib_v2.py:705] Step 7400 per-step time 0.455s\nI1018 02:22:24.388615 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.52153796,\n 'Loss/localization_loss': 0.2479364,\n 'Loss/regularization_loss': 0.50324523,\n 'Loss/total_loss': 1.2727196,\n 'learning_rate': 0.03480181}\nI1018 02:23:10.224660 140662142089024 model_lib_v2.py:705] Step 7500 per-step time 0.458s\nI1018 02:23:10.225003 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.40705517,\n 'Loss/localization_loss': 0.20581599,\n 'Loss/regularization_loss': 0.49210516,\n 'Loss/total_loss': 1.1049763,\n 'learning_rate': 0.034616716}\nI1018 02:23:55.938834 140662142089024 model_lib_v2.py:705] Step 7600 per-step time 0.457s\nI1018 02:23:55.939183 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4372451,\n 'Loss/localization_loss': 0.21812916,\n 'Loss/regularization_loss': 0.4811938,\n 'Loss/total_loss': 1.1365681,\n 'learning_rate': 0.0344289}\nI1018 02:24:41.599331 140662142089024 model_lib_v2.py:705] Step 7700 per-step time 0.457s\nI1018 02:24:41.599657 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5111623,\n 'Loss/localization_loss': 0.2614871,\n 'Loss/regularization_loss': 0.4712053,\n 'Loss/total_loss': 1.2438548,\n 'learning_rate': 0.03423839}\nI1018 02:25:27.353837 140662142089024 model_lib_v2.py:705] Step 7800 per-step time 0.458s\nI1018 02:25:27.354160 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.30995598,\n 'Loss/localization_loss': 0.19907662,\n 'Loss/regularization_loss': 0.4612049,\n 'Loss/total_loss': 0.9702375,\n 'learning_rate': 0.03404522}\nI1018 02:26:13.027906 140662142089024 model_lib_v2.py:705] Step 7900 per-step time 0.457s\nI1018 02:26:13.028241 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.30993247,\n 'Loss/localization_loss': 0.12992522,\n 'Loss/regularization_loss': 0.45171717,\n 'Loss/total_loss': 0.89157486,\n 'learning_rate': 0.033849433}\nI1018 02:26:58.636479 140662142089024 model_lib_v2.py:705] Step 8000 per-step time 0.456s\nI1018 02:26:58.636797 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3593521,\n 'Loss/localization_loss': 0.26146674,\n 'Loss/regularization_loss': 0.44232777,\n 'Loss/total_loss': 1.0631466,\n 'learning_rate': 0.03365106}\nI1018 02:27:47.175363 140662142089024 model_lib_v2.py:705] Step 8100 per-step time 0.485s\nI1018 02:27:47.175724 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.43988824,\n 'Loss/localization_loss': 0.19188613,\n 'Loss/regularization_loss': 0.43371698,\n 'Loss/total_loss': 1.0654913,\n 'learning_rate': 0.033450145}\nI1018 02:28:32.660255 140662142089024 model_lib_v2.py:705] Step 8200 per-step time 0.455s\nI1018 02:28:32.660679 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.66109645,\n 'Loss/localization_loss': 0.40175518,\n 'Loss/regularization_loss': 0.4255074,\n 'Loss/total_loss': 1.4883591,\n 'learning_rate': 0.03324672}\nI1018 02:29:18.147849 140662142089024 model_lib_v2.py:705] Step 8300 per-step time 0.455s\nI1018 02:29:18.148236 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5514176,\n 'Loss/localization_loss': 0.25076622,\n 'Loss/regularization_loss': 0.4174353,\n 'Loss/total_loss': 1.219619,\n 'learning_rate': 0.033040818}\nI1018 02:30:03.771801 140662142089024 model_lib_v2.py:705] Step 8400 per-step time 0.456s\nI1018 02:30:03.772126 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.49888337,\n 'Loss/localization_loss': 0.27846044,\n 'Loss/regularization_loss': 0.4093361,\n 'Loss/total_loss': 1.1866798,\n 'learning_rate': 0.032832485}\nI1018 02:30:49.256979 140662142089024 model_lib_v2.py:705] Step 8500 per-step time 0.455s\nI1018 02:30:49.257447 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.48071557,\n 'Loss/localization_loss': 0.2645222,\n 'Loss/regularization_loss': 0.4017074,\n 'Loss/total_loss': 1.1469452,\n 'learning_rate': 0.032621756}\nI1018 02:31:34.784774 140662142089024 model_lib_v2.py:705] Step 8600 per-step time 0.455s\nI1018 02:31:34.785133 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.34494376,\n 'Loss/localization_loss': 0.06961894,\n 'Loss/regularization_loss': 0.3941561,\n 'Loss/total_loss': 0.8087188,\n 'learning_rate': 0.032408677}\nI1018 02:32:20.316423 140662142089024 model_lib_v2.py:705] Step 8700 per-step time 0.455s\nI1018 02:32:20.316780 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.30681002,\n 'Loss/localization_loss': 0.09884087,\n 'Loss/regularization_loss': 0.386966,\n 'Loss/total_loss': 0.79261684,\n 'learning_rate': 0.032193277}\nI1018 02:33:05.831885 140662142089024 model_lib_v2.py:705] Step 8800 per-step time 0.455s\nI1018 02:33:05.832216 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.424889,\n 'Loss/localization_loss': 0.32243022,\n 'Loss/regularization_loss': 0.38008812,\n 'Loss/total_loss': 1.1274073,\n 'learning_rate': 0.03197561}\nI1018 02:33:51.302736 140662142089024 model_lib_v2.py:705] Step 8900 per-step time 0.455s\nI1018 02:33:51.303068 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.40941918,\n 'Loss/localization_loss': 0.03534203,\n 'Loss/regularization_loss': 0.3733413,\n 'Loss/total_loss': 0.81810254,\n 'learning_rate': 0.031755704}\nI1018 02:34:36.836392 140662142089024 model_lib_v2.py:705] Step 9000 per-step time 0.455s\nI1018 02:34:36.836697 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.34132656,\n 'Loss/localization_loss': 0.102386884,\n 'Loss/regularization_loss': 0.36657852,\n 'Loss/total_loss': 0.81029195,\n 'learning_rate': 0.031533606}\nI1018 02:35:25.060213 140662142089024 model_lib_v2.py:705] Step 9100 per-step time 0.482s\nI1018 02:35:25.060566 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3902213,\n 'Loss/localization_loss': 0.059492115,\n 'Loss/regularization_loss': 0.3602227,\n 'Loss/total_loss': 0.8099361,\n 'learning_rate': 0.031309355}\nI1018 02:36:10.645205 140662142089024 model_lib_v2.py:705] Step 9200 per-step time 0.456s\nI1018 02:36:10.645558 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.4453299,\n 'Loss/localization_loss': 0.17842501,\n 'Loss/regularization_loss': 0.35398546,\n 'Loss/total_loss': 0.97774035,\n 'learning_rate': 0.031082997}\nI1018 02:36:56.167861 140662142089024 model_lib_v2.py:705] Step 9300 per-step time 0.455s\nI1018 02:36:56.168249 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.38168633,\n 'Loss/localization_loss': 0.10522817,\n 'Loss/regularization_loss': 0.34787065,\n 'Loss/total_loss': 0.83478516,\n 'learning_rate': 0.030854566}\nI1018 02:37:41.703655 140662142089024 model_lib_v2.py:705] Step 9400 per-step time 0.455s\nI1018 02:37:41.703996 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.36681682,\n 'Loss/localization_loss': 0.085577,\n 'Loss/regularization_loss': 0.3425419,\n 'Loss/total_loss': 0.7949357,\n 'learning_rate': 0.030624112}\nI1018 02:38:27.148123 140662142089024 model_lib_v2.py:705] Step 9500 per-step time 0.454s\nI1018 02:38:27.148461 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2631002,\n 'Loss/localization_loss': 0.17292161,\n 'Loss/regularization_loss': 0.3370083,\n 'Loss/total_loss': 0.77303016,\n 'learning_rate': 0.030391678}\nI1018 02:39:12.561262 140662142089024 model_lib_v2.py:705] Step 9600 per-step time 0.454s\nI1018 02:39:12.561578 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.34884286,\n 'Loss/localization_loss': 0.1031393,\n 'Loss/regularization_loss': 0.33190563,\n 'Loss/total_loss': 0.7838878,\n 'learning_rate': 0.030157303}\nI1018 02:39:58.005660 140662142089024 model_lib_v2.py:705] Step 9700 per-step time 0.454s\nI1018 02:39:58.005990 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.31571227,\n 'Loss/localization_loss': 0.2515239,\n 'Loss/regularization_loss': 0.32684404,\n 'Loss/total_loss': 0.8940802,\n 'learning_rate': 0.029921034}\nI1018 02:40:43.406031 140662142089024 model_lib_v2.py:705] Step 9800 per-step time 0.454s\nI1018 02:40:43.406353 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.35514095,\n 'Loss/localization_loss': 0.14588012,\n 'Loss/regularization_loss': 0.32187167,\n 'Loss/total_loss': 0.8228927,\n 'learning_rate': 0.029682912}\nI1018 02:41:28.790733 140662142089024 model_lib_v2.py:705] Step 9900 per-step time 0.454s\nI1018 02:41:28.791085 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.47235388,\n 'Loss/localization_loss': 0.13694969,\n 'Loss/regularization_loss': 0.3171877,\n 'Loss/total_loss': 0.92649126,\n 'learning_rate': 0.029442988}\nI1018 02:42:14.136637 140662142089024 model_lib_v2.py:705] Step 10000 per-step time 0.453s\nI1018 02:42:14.136977 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2755795,\n 'Loss/localization_loss': 0.09009798,\n 'Loss/regularization_loss': 0.3125358,\n 'Loss/total_loss': 0.67821324,\n 'learning_rate': 0.029201299}\nI1018 02:43:02.396875 140662142089024 model_lib_v2.py:705] Step 10100 per-step time 0.483s\nI1018 02:43:02.397212 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.28177685,\n 'Loss/localization_loss': 0.065035135,\n 'Loss/regularization_loss': 0.30761182,\n 'Loss/total_loss': 0.65442383,\n 'learning_rate': 0.028957896}\nI1018 02:43:47.810090 140662142089024 model_lib_v2.py:705] Step 10200 per-step time 0.454s\nI1018 02:43:47.810422 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.33132374,\n 'Loss/localization_loss': 0.17658862,\n 'Loss/regularization_loss': 0.30319974,\n 'Loss/total_loss': 0.8111121,\n 'learning_rate': 0.028712818}\nI1018 02:44:33.359465 140662142089024 model_lib_v2.py:705] Step 10300 per-step time 0.455s\nI1018 02:44:33.359794 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.35616913,\n 'Loss/localization_loss': 0.13433252,\n 'Loss/regularization_loss': 0.29890925,\n 'Loss/total_loss': 0.7894109,\n 'learning_rate': 0.028466115}\nI1018 02:45:18.790441 140662142089024 model_lib_v2.py:705] Step 10400 per-step time 0.454s\nI1018 02:45:18.790751 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.44439155,\n 'Loss/localization_loss': 0.08498815,\n 'Loss/regularization_loss': 0.29471,\n 'Loss/total_loss': 0.82408977,\n 'learning_rate': 0.028217835}\nI1018 02:46:04.246126 140662142089024 model_lib_v2.py:705] Step 10500 per-step time 0.455s\nI1018 02:46:04.246464 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21690983,\n 'Loss/localization_loss': 0.08020714,\n 'Loss/regularization_loss': 0.2907397,\n 'Loss/total_loss': 0.58785665,\n 'learning_rate': 0.027968023}\nI1018 02:46:50.254030 140662142089024 model_lib_v2.py:705] Step 10600 per-step time 0.460s\nI1018 02:46:50.254350 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.39128298,\n 'Loss/localization_loss': 0.15061738,\n 'Loss/regularization_loss': 0.28697175,\n 'Loss/total_loss': 0.8288721,\n 'learning_rate': 0.027716719}\nI1018 02:47:36.157314 140662142089024 model_lib_v2.py:705] Step 10700 per-step time 0.459s\nI1018 02:47:36.157671 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3906589,\n 'Loss/localization_loss': 0.12868237,\n 'Loss/regularization_loss': 0.28314185,\n 'Loss/total_loss': 0.80248314,\n 'learning_rate': 0.02746398}\nI1018 02:48:21.836731 140662142089024 model_lib_v2.py:705] Step 10800 per-step time 0.457s\nI1018 02:48:21.837078 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.315211,\n 'Loss/localization_loss': 0.16163315,\n 'Loss/regularization_loss': 0.2792981,\n 'Loss/total_loss': 0.75614226,\n 'learning_rate': 0.027209844}\nI1018 02:49:07.493304 140662142089024 model_lib_v2.py:705] Step 10900 per-step time 0.457s\nI1018 02:49:07.493614 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.29864866,\n 'Loss/localization_loss': 0.06256137,\n 'Loss/regularization_loss': 0.27552438,\n 'Loss/total_loss': 0.6367344,\n 'learning_rate': 0.026954366}\nI1018 02:49:53.035408 140662142089024 model_lib_v2.py:705] Step 11000 per-step time 0.455s\nI1018 02:49:53.035756 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26242983,\n 'Loss/localization_loss': 0.055744752,\n 'Loss/regularization_loss': 0.27192092,\n 'Loss/total_loss': 0.5900955,\n 'learning_rate': 0.026697593}\nI1018 02:50:41.443877 140662142089024 model_lib_v2.py:705] Step 11100 per-step time 0.484s\nI1018 02:50:41.444256 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.27061677,\n 'Loss/localization_loss': 0.19156593,\n 'Loss/regularization_loss': 0.26876992,\n 'Loss/total_loss': 0.7309526,\n 'learning_rate': 0.026439566}\nI1018 02:51:26.902945 140662142089024 model_lib_v2.py:705] Step 11200 per-step time 0.455s\nI1018 02:51:26.903265 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25573608,\n 'Loss/localization_loss': 0.19347607,\n 'Loss/regularization_loss': 0.2654251,\n 'Loss/total_loss': 0.7146372,\n 'learning_rate': 0.026180338}\nI1018 02:52:12.556536 140662142089024 model_lib_v2.py:705] Step 11300 per-step time 0.457s\nI1018 02:52:12.556859 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3006058,\n 'Loss/localization_loss': 0.10625508,\n 'Loss/regularization_loss': 0.26195446,\n 'Loss/total_loss': 0.6688153,\n 'learning_rate': 0.025919959}\nI1018 02:52:58.398860 140662142089024 model_lib_v2.py:705] Step 11400 per-step time 0.458s\nI1018 02:52:58.399238 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.34343565,\n 'Loss/localization_loss': 0.19204293,\n 'Loss/regularization_loss': 0.25838226,\n 'Loss/total_loss': 0.79386085,\n 'learning_rate': 0.025658473}\nI1018 02:53:44.272700 140662142089024 model_lib_v2.py:705] Step 11500 per-step time 0.459s\nI1018 02:53:44.273014 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.40937322,\n 'Loss/localization_loss': 0.23507616,\n 'Loss/regularization_loss': 0.25498953,\n 'Loss/total_loss': 0.8994389,\n 'learning_rate': 0.025395937}\nI1018 02:54:29.987765 140662142089024 model_lib_v2.py:705] Step 11600 per-step time 0.457s\nI1018 02:54:29.988105 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.43203545,\n 'Loss/localization_loss': 0.22359261,\n 'Loss/regularization_loss': 0.25166896,\n 'Loss/total_loss': 0.907297,\n 'learning_rate': 0.025132386}\nI1018 02:55:15.818546 140662142089024 model_lib_v2.py:705] Step 11700 per-step time 0.458s\nI1018 02:55:15.818853 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2640007,\n 'Loss/localization_loss': 0.14009151,\n 'Loss/regularization_loss': 0.24869852,\n 'Loss/total_loss': 0.6527908,\n 'learning_rate': 0.024867883}\nI1018 02:56:01.463057 140662142089024 model_lib_v2.py:705] Step 11800 per-step time 0.456s\nI1018 02:56:01.463374 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.35414648,\n 'Loss/localization_loss': 0.047104727,\n 'Loss/regularization_loss': 0.24579312,\n 'Loss/total_loss': 0.6470443,\n 'learning_rate': 0.024602469}\nI1018 02:56:46.975186 140662142089024 model_lib_v2.py:705] Step 11900 per-step time 0.455s\nI1018 02:56:46.975533 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3126651,\n 'Loss/localization_loss': 0.14907935,\n 'Loss/regularization_loss': 0.24325266,\n 'Loss/total_loss': 0.7049971,\n 'learning_rate': 0.024336198}\nI1018 02:57:32.644003 140662142089024 model_lib_v2.py:705] Step 12000 per-step time 0.457s\nI1018 02:57:32.644316 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.31976485,\n 'Loss/localization_loss': 0.06330481,\n 'Loss/regularization_loss': 0.24081787,\n 'Loss/total_loss': 0.62388754,\n 'learning_rate': 0.024069117}\nI1018 02:58:21.253288 140662142089024 model_lib_v2.py:705] Step 12100 per-step time 0.486s\nI1018 02:58:21.253629 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.31321692,\n 'Loss/localization_loss': 0.16098608,\n 'Loss/regularization_loss': 0.23851314,\n 'Loss/total_loss': 0.71271616,\n 'learning_rate': 0.02380128}\nI1018 02:59:06.628707 140662142089024 model_lib_v2.py:705] Step 12200 per-step time 0.454s\nI1018 02:59:06.629049 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.39856854,\n 'Loss/localization_loss': 0.17821316,\n 'Loss/regularization_loss': 0.23652215,\n 'Loss/total_loss': 0.8133038,\n 'learning_rate': 0.023532731}\nI1018 02:59:51.979103 140662142089024 model_lib_v2.py:705] Step 12300 per-step time 0.453s\nI1018 02:59:51.979415 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.44835377,\n 'Loss/localization_loss': 0.15982996,\n 'Loss/regularization_loss': 0.23441805,\n 'Loss/total_loss': 0.8426018,\n 'learning_rate': 0.023263523}\nI1018 03:00:37.376532 140662142089024 model_lib_v2.py:705] Step 12400 per-step time 0.454s\nI1018 03:00:37.376857 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21270123,\n 'Loss/localization_loss': 0.049692113,\n 'Loss/regularization_loss': 0.2324045,\n 'Loss/total_loss': 0.49479786,\n 'learning_rate': 0.022993708}\nI1018 03:01:22.911620 140662142089024 model_lib_v2.py:705] Step 12500 per-step time 0.455s\nI1018 03:01:22.911917 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.29260686,\n 'Loss/localization_loss': 0.07820609,\n 'Loss/regularization_loss': 0.23018861,\n 'Loss/total_loss': 0.6010015,\n 'learning_rate': 0.022723334}\nI1018 03:02:08.300727 140662142089024 model_lib_v2.py:705] Step 12600 per-step time 0.454s\nI1018 03:02:08.301065 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.33599806,\n 'Loss/localization_loss': 0.17543,\n 'Loss/regularization_loss': 0.22831768,\n 'Loss/total_loss': 0.73974574,\n 'learning_rate': 0.02245245}\nI1018 03:02:53.739852 140662142089024 model_lib_v2.py:705] Step 12700 per-step time 0.454s\nI1018 03:02:53.740200 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20329735,\n 'Loss/localization_loss': 0.06785994,\n 'Loss/regularization_loss': 0.22624128,\n 'Loss/total_loss': 0.49739856,\n 'learning_rate': 0.022181105}\nI1018 03:03:39.152773 140662142089024 model_lib_v2.py:705] Step 12800 per-step time 0.454s\nI1018 03:03:39.153163 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.5268039,\n 'Loss/localization_loss': 0.15454519,\n 'Loss/regularization_loss': 0.22428475,\n 'Loss/total_loss': 0.9056338,\n 'learning_rate': 0.021909358}\nI1018 03:04:24.652525 140662142089024 model_lib_v2.py:705] Step 12900 per-step time 0.455s\nI1018 03:04:24.652922 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.31762525,\n 'Loss/localization_loss': 0.06753111,\n 'Loss/regularization_loss': 0.22235876,\n 'Loss/total_loss': 0.60751516,\n 'learning_rate': 0.021637257}\nI1018 03:05:10.159882 140662142089024 model_lib_v2.py:705] Step 13000 per-step time 0.455s\nI1018 03:05:10.160243 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.37415984,\n 'Loss/localization_loss': 0.15220073,\n 'Loss/regularization_loss': 0.22039843,\n 'Loss/total_loss': 0.746759,\n 'learning_rate': 0.021364845}\nI1018 03:05:59.540535 140662142089024 model_lib_v2.py:705] Step 13100 per-step time 0.494s\nI1018 03:05:59.540876 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.46149522,\n 'Loss/localization_loss': 0.14729819,\n 'Loss/regularization_loss': 0.21835767,\n 'Loss/total_loss': 0.82715106,\n 'learning_rate': 0.021092184}\nI1018 03:06:44.975708 140662142089024 model_lib_v2.py:705] Step 13200 per-step time 0.454s\nI1018 03:06:44.976042 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.28333113,\n 'Loss/localization_loss': 0.048621688,\n 'Loss/regularization_loss': 0.21663345,\n 'Loss/total_loss': 0.54858625,\n 'learning_rate': 0.020819314}\nI1018 03:07:30.547574 140662142089024 model_lib_v2.py:705] Step 13300 per-step time 0.456s\nI1018 03:07:30.547909 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.31361052,\n 'Loss/localization_loss': 0.06428357,\n 'Loss/regularization_loss': 0.21491382,\n 'Loss/total_loss': 0.5928079,\n 'learning_rate': 0.020546295}\nI1018 03:08:15.995050 140662142089024 model_lib_v2.py:705] Step 13400 per-step time 0.454s\nI1018 03:08:15.995413 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.27237898,\n 'Loss/localization_loss': 0.021136072,\n 'Loss/regularization_loss': 0.21320423,\n 'Loss/total_loss': 0.5067193,\n 'learning_rate': 0.020273173}\nI1018 03:09:01.484091 140662142089024 model_lib_v2.py:705] Step 13500 per-step time 0.455s\nI1018 03:09:01.484421 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.364384,\n 'Loss/localization_loss': 0.18188432,\n 'Loss/regularization_loss': 0.21144755,\n 'Loss/total_loss': 0.7577158,\n 'learning_rate': 0.019999998}\nI1018 03:09:46.947435 140662142089024 model_lib_v2.py:705] Step 13600 per-step time 0.455s\nI1018 03:09:46.947780 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2883101,\n 'Loss/localization_loss': 0.10572502,\n 'Loss/regularization_loss': 0.20986693,\n 'Loss/total_loss': 0.60390204,\n 'learning_rate': 0.019726824}\nI1018 03:10:32.430456 140662142089024 model_lib_v2.py:705] Step 13700 per-step time 0.455s\nI1018 03:10:32.430902 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.23798895,\n 'Loss/localization_loss': 0.03839443,\n 'Loss/regularization_loss': 0.20817173,\n 'Loss/total_loss': 0.48455513,\n 'learning_rate': 0.0194537}\nI1018 03:11:17.863692 140662142089024 model_lib_v2.py:705] Step 13800 per-step time 0.454s\nI1018 03:11:17.864024 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.35348034,\n 'Loss/localization_loss': 0.24022664,\n 'Loss/regularization_loss': 0.20666052,\n 'Loss/total_loss': 0.8003675,\n 'learning_rate': 0.019180683}\nI1018 03:12:03.337711 140662142089024 model_lib_v2.py:705] Step 13900 per-step time 0.455s\nI1018 03:12:03.338033 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25141948,\n 'Loss/localization_loss': 0.11560721,\n 'Loss/regularization_loss': 0.20510869,\n 'Loss/total_loss': 0.5721354,\n 'learning_rate': 0.018907815}\nI1018 03:12:48.905651 140662142089024 model_lib_v2.py:705] Step 14000 per-step time 0.456s\nI1018 03:12:48.906015 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.29967836,\n 'Loss/localization_loss': 0.037681267,\n 'Loss/regularization_loss': 0.2036346,\n 'Loss/total_loss': 0.5409942,\n 'learning_rate': 0.01863515}\nI1018 03:13:37.107191 140662142089024 model_lib_v2.py:705] Step 14100 per-step time 0.482s\nI1018 03:13:37.107535 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.306776,\n 'Loss/localization_loss': 0.19967152,\n 'Loss/regularization_loss': 0.20222932,\n 'Loss/total_loss': 0.7086768,\n 'learning_rate': 0.018362742}\nI1018 03:14:22.422507 140662142089024 model_lib_v2.py:705] Step 14200 per-step time 0.453s\nI1018 03:14:22.422829 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.28084674,\n 'Loss/localization_loss': 0.046266574,\n 'Loss/regularization_loss': 0.2009338,\n 'Loss/total_loss': 0.52804714,\n 'learning_rate': 0.01809064}\nI1018 03:15:07.864062 140662142089024 model_lib_v2.py:705] Step 14300 per-step time 0.454s\nI1018 03:15:07.864408 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21929562,\n 'Loss/localization_loss': 0.032004524,\n 'Loss/regularization_loss': 0.19934787,\n 'Loss/total_loss': 0.450648,\n 'learning_rate': 0.017818892}\nI1018 03:15:53.326739 140662142089024 model_lib_v2.py:705] Step 14400 per-step time 0.455s\nI1018 03:15:53.327102 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3422963,\n 'Loss/localization_loss': 0.29705185,\n 'Loss/regularization_loss': 0.19795182,\n 'Loss/total_loss': 0.83729994,\n 'learning_rate': 0.01754755}\nI1018 03:16:38.680646 140662142089024 model_lib_v2.py:705] Step 14500 per-step time 0.454s\nI1018 03:16:38.681024 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.23492861,\n 'Loss/localization_loss': 0.04791142,\n 'Loss/regularization_loss': 0.19662704,\n 'Loss/total_loss': 0.47946706,\n 'learning_rate': 0.017276663}\nI1018 03:17:24.184715 140662142089024 model_lib_v2.py:705] Step 14600 per-step time 0.455s\nI1018 03:17:24.185048 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3992692,\n 'Loss/localization_loss': 0.11504624,\n 'Loss/regularization_loss': 0.19530146,\n 'Loss/total_loss': 0.7096169,\n 'learning_rate': 0.01700629}\nI1018 03:18:09.584364 140662142089024 model_lib_v2.py:705] Step 14700 per-step time 0.454s\nI1018 03:18:09.584688 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22062299,\n 'Loss/localization_loss': 0.08342408,\n 'Loss/regularization_loss': 0.19394627,\n 'Loss/total_loss': 0.4979933,\n 'learning_rate': 0.016736476}\nI1018 03:18:55.071529 140662142089024 model_lib_v2.py:705] Step 14800 per-step time 0.455s\nI1018 03:18:55.071837 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.33078045,\n 'Loss/localization_loss': 0.10353135,\n 'Loss/regularization_loss': 0.19260962,\n 'Loss/total_loss': 0.6269214,\n 'learning_rate': 0.016467266}\nI1018 03:19:40.540756 140662142089024 model_lib_v2.py:705] Step 14900 per-step time 0.455s\nI1018 03:19:40.541085 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26831284,\n 'Loss/localization_loss': 0.06960427,\n 'Loss/regularization_loss': 0.19143392,\n 'Loss/total_loss': 0.529351,\n 'learning_rate': 0.016198717}\nI1018 03:20:25.969607 140662142089024 model_lib_v2.py:705] Step 15000 per-step time 0.454s\nI1018 03:20:25.969919 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20692703,\n 'Loss/localization_loss': 0.16868404,\n 'Loss/regularization_loss': 0.19028313,\n 'Loss/total_loss': 0.56589425,\n 'learning_rate': 0.015930876}\nI1018 03:21:14.359729 140662142089024 model_lib_v2.py:705] Step 15100 per-step time 0.484s\nI1018 03:21:14.360095 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26040602,\n 'Loss/localization_loss': 0.12764731,\n 'Loss/regularization_loss': 0.18902469,\n 'Loss/total_loss': 0.577078,\n 'learning_rate': 0.015663799}\nI1018 03:21:59.959764 140662142089024 model_lib_v2.py:705] Step 15200 per-step time 0.456s\nI1018 03:21:59.960101 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22634384,\n 'Loss/localization_loss': 0.1279132,\n 'Loss/regularization_loss': 0.18777208,\n 'Loss/total_loss': 0.54202914,\n 'learning_rate': 0.015397527}\nI1018 03:22:45.631655 140662142089024 model_lib_v2.py:705] Step 15300 per-step time 0.457s\nI1018 03:22:45.632009 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25326836,\n 'Loss/localization_loss': 0.08591524,\n 'Loss/regularization_loss': 0.1864183,\n 'Loss/total_loss': 0.5256019,\n 'learning_rate': 0.015132114}\nI1018 03:23:31.324046 140662142089024 model_lib_v2.py:705] Step 15400 per-step time 0.457s\nI1018 03:23:31.324368 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26421377,\n 'Loss/localization_loss': 0.19648498,\n 'Loss/regularization_loss': 0.1849642,\n 'Loss/total_loss': 0.6456629,\n 'learning_rate': 0.014867609}\nI1018 03:24:17.030259 140662142089024 model_lib_v2.py:705] Step 15500 per-step time 0.457s\nI1018 03:24:17.030587 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2632699,\n 'Loss/localization_loss': 0.15872449,\n 'Loss/regularization_loss': 0.18368967,\n 'Loss/total_loss': 0.60568404,\n 'learning_rate': 0.014604063}\nI1018 03:25:02.661324 140662142089024 model_lib_v2.py:705] Step 15600 per-step time 0.456s\nI1018 03:25:02.661666 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.3938567,\n 'Loss/localization_loss': 0.18722618,\n 'Loss/regularization_loss': 0.18241376,\n 'Loss/total_loss': 0.76349664,\n 'learning_rate': 0.014341523}\nI1018 03:25:48.306766 140662142089024 model_lib_v2.py:705] Step 15700 per-step time 0.456s\nI1018 03:25:48.307090 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25825274,\n 'Loss/localization_loss': 0.069410145,\n 'Loss/regularization_loss': 0.18127461,\n 'Loss/total_loss': 0.5089375,\n 'learning_rate': 0.01408004}\nI1018 03:26:33.776721 140662142089024 model_lib_v2.py:705] Step 15800 per-step time 0.455s\nI1018 03:26:33.777067 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26498526,\n 'Loss/localization_loss': 0.06774844,\n 'Loss/regularization_loss': 0.18021114,\n 'Loss/total_loss': 0.5129448,\n 'learning_rate': 0.013819658}\nI1018 03:27:19.471523 140662142089024 model_lib_v2.py:705] Step 15900 per-step time 0.457s\nI1018 03:27:19.471846 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26259142,\n 'Loss/localization_loss': 0.18027958,\n 'Loss/regularization_loss': 0.17922449,\n 'Loss/total_loss': 0.62209547,\n 'learning_rate': 0.013560432}\nI1018 03:28:05.079669 140662142089024 model_lib_v2.py:705] Step 16000 per-step time 0.456s\nI1018 03:28:05.080006 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22447333,\n 'Loss/localization_loss': 0.13243495,\n 'Loss/regularization_loss': 0.17830391,\n 'Loss/total_loss': 0.53521216,\n 'learning_rate': 0.013302408}\nI1018 03:28:53.331879 140662142089024 model_lib_v2.py:705] Step 16100 per-step time 0.483s\nI1018 03:28:53.332240 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25740567,\n 'Loss/localization_loss': 0.06844795,\n 'Loss/regularization_loss': 0.17749731,\n 'Loss/total_loss': 0.503351,\n 'learning_rate': 0.013045632}\nI1018 03:29:38.995089 140662142089024 model_lib_v2.py:705] Step 16200 per-step time 0.457s\nI1018 03:29:38.995485 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.18961768,\n 'Loss/localization_loss': 0.120401084,\n 'Loss/regularization_loss': 0.17670041,\n 'Loss/total_loss': 0.4867192,\n 'learning_rate': 0.012790153}\nI1018 03:30:24.650970 140662142089024 model_lib_v2.py:705] Step 16300 per-step time 0.457s\nI1018 03:30:24.651299 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.38719416,\n 'Loss/localization_loss': 0.12243273,\n 'Loss/regularization_loss': 0.1758543,\n 'Loss/total_loss': 0.6854812,\n 'learning_rate': 0.012536017}\nI1018 03:31:10.138142 140662142089024 model_lib_v2.py:705] Step 16400 per-step time 0.455s\nI1018 03:31:10.138450 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.18342164,\n 'Loss/localization_loss': 0.034307692,\n 'Loss/regularization_loss': 0.17504713,\n 'Loss/total_loss': 0.3927765,\n 'learning_rate': 0.01228328}\nI1018 03:31:55.650293 140662142089024 model_lib_v2.py:705] Step 16500 per-step time 0.455s\nI1018 03:31:55.650625 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25109524,\n 'Loss/localization_loss': 0.06087304,\n 'Loss/regularization_loss': 0.17419346,\n 'Loss/total_loss': 0.48616174,\n 'learning_rate': 0.012031979}\nI1018 03:32:41.136302 140662142089024 model_lib_v2.py:705] Step 16600 per-step time 0.455s\nI1018 03:32:41.136672 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2743669,\n 'Loss/localization_loss': 0.018573519,\n 'Loss/regularization_loss': 0.17338859,\n 'Loss/total_loss': 0.46632898,\n 'learning_rate': 0.011782162}\nI1018 03:33:26.526998 140662142089024 model_lib_v2.py:705] Step 16700 per-step time 0.454s\nI1018 03:33:26.527316 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.2179807,\n 'Loss/localization_loss': 0.06372452,\n 'Loss/regularization_loss': 0.17264181,\n 'Loss/total_loss': 0.454347,\n 'learning_rate': 0.01153388}\nI1018 03:34:11.897840 140662142089024 model_lib_v2.py:705] Step 16800 per-step time 0.454s\nI1018 03:34:11.898179 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.28435272,\n 'Loss/localization_loss': 0.080466636,\n 'Loss/regularization_loss': 0.17189945,\n 'Loss/total_loss': 0.53671885,\n 'learning_rate': 0.01128718}\nI1018 03:34:57.387442 140662142089024 model_lib_v2.py:705] Step 16900 per-step time 0.455s\nI1018 03:34:57.387764 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.30694506,\n 'Loss/localization_loss': 0.07765718,\n 'Loss/regularization_loss': 0.17107958,\n 'Loss/total_loss': 0.5556818,\n 'learning_rate': 0.011042106}\nI1018 03:35:42.900354 140662142089024 model_lib_v2.py:705] Step 17000 per-step time 0.455s\nI1018 03:35:42.900673 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.24241842,\n 'Loss/localization_loss': 0.15860805,\n 'Loss/regularization_loss': 0.1702869,\n 'Loss/total_loss': 0.5713134,\n 'learning_rate': 0.010798697}\nI1018 03:36:31.149552 140662142089024 model_lib_v2.py:705] Step 17100 per-step time 0.482s\nI1018 03:36:31.149911 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.32117403,\n 'Loss/localization_loss': 0.22678947,\n 'Loss/regularization_loss': 0.16961795,\n 'Loss/total_loss': 0.71758145,\n 'learning_rate': 0.010557013}\nI1018 03:37:16.619228 140662142089024 model_lib_v2.py:705] Step 17200 per-step time 0.455s\nI1018 03:37:16.619558 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25848675,\n 'Loss/localization_loss': 0.11859614,\n 'Loss/regularization_loss': 0.16893207,\n 'Loss/total_loss': 0.54601496,\n 'learning_rate': 0.0103170825}\nI1018 03:38:02.034044 140662142089024 model_lib_v2.py:705] Step 17300 per-step time 0.454s\nI1018 03:38:02.034463 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.29374278,\n 'Loss/localization_loss': 0.08308401,\n 'Loss/regularization_loss': 0.16821961,\n 'Loss/total_loss': 0.5450464,\n 'learning_rate': 0.010078964}\nI1018 03:38:47.609992 140662142089024 model_lib_v2.py:705] Step 17400 per-step time 0.456s\nI1018 03:38:47.610327 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.27103293,\n 'Loss/localization_loss': 0.067969285,\n 'Loss/regularization_loss': 0.16752504,\n 'Loss/total_loss': 0.5065273,\n 'learning_rate': 0.009842696}\nI1018 03:39:33.103285 140662142089024 model_lib_v2.py:705] Step 17500 per-step time 0.455s\nI1018 03:39:33.103623 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.19855033,\n 'Loss/localization_loss': 0.04995264,\n 'Loss/regularization_loss': 0.16681334,\n 'Loss/total_loss': 0.4153163,\n 'learning_rate': 0.00960832}\nI1018 03:40:18.401345 140662142089024 model_lib_v2.py:705] Step 17600 per-step time 0.453s\nI1018 03:40:18.401686 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22657055,\n 'Loss/localization_loss': 0.048674837,\n 'Loss/regularization_loss': 0.16614257,\n 'Loss/total_loss': 0.44138795,\n 'learning_rate': 0.009375882}\nI1018 03:41:04.045661 140662142089024 model_lib_v2.py:705] Step 17700 per-step time 0.456s\nI1018 03:41:04.045987 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.39343306,\n 'Loss/localization_loss': 0.111309074,\n 'Loss/regularization_loss': 0.16549541,\n 'Loss/total_loss': 0.67023754,\n 'learning_rate': 0.00914543}\nI1018 03:41:49.527951 140662142089024 model_lib_v2.py:705] Step 17800 per-step time 0.455s\nI1018 03:41:49.528263 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25480992,\n 'Loss/localization_loss': 0.024874832,\n 'Loss/regularization_loss': 0.16485925,\n 'Loss/total_loss': 0.44454402,\n 'learning_rate': 0.008917004}\nI1018 03:42:34.903543 140662142089024 model_lib_v2.py:705] Step 17900 per-step time 0.454s\nI1018 03:42:34.903860 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.23889725,\n 'Loss/localization_loss': 0.12147872,\n 'Loss/regularization_loss': 0.16421661,\n 'Loss/total_loss': 0.5245926,\n 'learning_rate': 0.00869064}\nI1018 03:43:20.316944 140662142089024 model_lib_v2.py:705] Step 18000 per-step time 0.454s\nI1018 03:43:20.317246 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21027161,\n 'Loss/localization_loss': 0.026875686,\n 'Loss/regularization_loss': 0.16358304,\n 'Loss/total_loss': 0.4007303,\n 'learning_rate': 0.008466393}\nI1018 03:44:08.633214 140662142089024 model_lib_v2.py:705] Step 18100 per-step time 0.483s\nI1018 03:44:08.633563 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.27128723,\n 'Loss/localization_loss': 0.023995172,\n 'Loss/regularization_loss': 0.1629613,\n 'Loss/total_loss': 0.45824373,\n 'learning_rate': 0.008244291}\nI1018 03:44:54.014493 140662142089024 model_lib_v2.py:705] Step 18200 per-step time 0.454s\nI1018 03:44:54.014811 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.19827065,\n 'Loss/localization_loss': 0.0495257,\n 'Loss/regularization_loss': 0.16235912,\n 'Loss/total_loss': 0.41015548,\n 'learning_rate': 0.008024387}\nI1018 03:45:39.429270 140662142089024 model_lib_v2.py:705] Step 18300 per-step time 0.454s\nI1018 03:45:39.429652 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.24620375,\n 'Loss/localization_loss': 0.11689864,\n 'Loss/regularization_loss': 0.16173585,\n 'Loss/total_loss': 0.5248382,\n 'learning_rate': 0.0078067183}\nI1018 03:46:24.880681 140662142089024 model_lib_v2.py:705] Step 18400 per-step time 0.455s\nI1018 03:46:24.881036 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.18357803,\n 'Loss/localization_loss': 0.027943691,\n 'Loss/regularization_loss': 0.16116934,\n 'Loss/total_loss': 0.37269107,\n 'learning_rate': 0.00759132}\nI1018 03:47:10.181472 140662142089024 model_lib_v2.py:705] Step 18500 per-step time 0.453s\nI1018 03:47:10.181812 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20863849,\n 'Loss/localization_loss': 0.035055026,\n 'Loss/regularization_loss': 0.16058911,\n 'Loss/total_loss': 0.40428263,\n 'learning_rate': 0.0073782397}\nI1018 03:47:55.683263 140662142089024 model_lib_v2.py:705] Step 18600 per-step time 0.455s\nI1018 03:47:55.683588 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20508575,\n 'Loss/localization_loss': 0.05345147,\n 'Loss/regularization_loss': 0.16002546,\n 'Loss/total_loss': 0.41856268,\n 'learning_rate': 0.007167512}\nI1018 03:48:41.099124 140662142089024 model_lib_v2.py:705] Step 18700 per-step time 0.454s\nI1018 03:48:41.099473 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21610166,\n 'Loss/localization_loss': 0.060969554,\n 'Loss/regularization_loss': 0.15944886,\n 'Loss/total_loss': 0.4365201,\n 'learning_rate': 0.006959181}\nI1018 03:49:26.435834 140662142089024 model_lib_v2.py:705] Step 18800 per-step time 0.453s\nI1018 03:49:26.436157 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22581726,\n 'Loss/localization_loss': 0.03330021,\n 'Loss/regularization_loss': 0.15891759,\n 'Loss/total_loss': 0.41803506,\n 'learning_rate': 0.0067532836}\nI1018 03:50:11.982236 140662142089024 model_lib_v2.py:705] Step 18900 per-step time 0.455s\nI1018 03:50:11.982583 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21280672,\n 'Loss/localization_loss': 0.015729949,\n 'Loss/regularization_loss': 0.15844826,\n 'Loss/total_loss': 0.3869849,\n 'learning_rate': 0.006549853}\nI1018 03:50:57.464586 140662142089024 model_lib_v2.py:705] Step 19000 per-step time 0.455s\nI1018 03:50:57.464898 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20588788,\n 'Loss/localization_loss': 0.036931433,\n 'Loss/regularization_loss': 0.15792944,\n 'Loss/total_loss': 0.40074873,\n 'learning_rate': 0.0063489364}\nI1018 03:51:45.936621 140662142089024 model_lib_v2.py:705] Step 19100 per-step time 0.485s\nI1018 03:51:45.936973 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.23944312,\n 'Loss/localization_loss': 0.08905828,\n 'Loss/regularization_loss': 0.15737548,\n 'Loss/total_loss': 0.48587692,\n 'learning_rate': 0.006150566}\nI1018 03:52:31.598856 140662142089024 model_lib_v2.py:705] Step 19200 per-step time 0.457s\nI1018 03:52:31.599203 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.21424246,\n 'Loss/localization_loss': 0.07177408,\n 'Loss/regularization_loss': 0.1568179,\n 'Loss/total_loss': 0.44283444,\n 'learning_rate': 0.005954777}\nI1018 03:53:17.243462 140662142089024 model_lib_v2.py:705] Step 19300 per-step time 0.456s\nI1018 03:53:17.243808 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.1817122,\n 'Loss/localization_loss': 0.051526614,\n 'Loss/regularization_loss': 0.15627564,\n 'Loss/total_loss': 0.38951445,\n 'learning_rate': 0.0057616076}\nI1018 03:54:02.966347 140662142089024 model_lib_v2.py:705] Step 19400 per-step time 0.457s\nI1018 03:54:02.966675 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.28642485,\n 'Loss/localization_loss': 0.04123182,\n 'Loss/regularization_loss': 0.15581445,\n 'Loss/total_loss': 0.48347113,\n 'learning_rate': 0.005571098}\nI1018 03:54:48.689849 140662142089024 model_lib_v2.py:705] Step 19500 per-step time 0.457s\nI1018 03:54:48.690173 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.26630187,\n 'Loss/localization_loss': 0.11113473,\n 'Loss/regularization_loss': 0.15530705,\n 'Loss/total_loss': 0.5327437,\n 'learning_rate': 0.0053832806}\nI1018 03:55:34.444096 140662142089024 model_lib_v2.py:705] Step 19600 per-step time 0.458s\nI1018 03:55:34.444410 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.20207283,\n 'Loss/localization_loss': 0.108289555,\n 'Loss/regularization_loss': 0.15482837,\n 'Loss/total_loss': 0.46519077,\n 'learning_rate': 0.0051981867}\nI1018 03:56:19.961780 140662142089024 model_lib_v2.py:705] Step 19700 per-step time 0.455s\nI1018 03:56:19.962128 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.24143437,\n 'Loss/localization_loss': 0.087303095,\n 'Loss/regularization_loss': 0.15438709,\n 'Loss/total_loss': 0.48312455,\n 'learning_rate': 0.0050158584}\nI1018 03:57:05.510473 140662142089024 model_lib_v2.py:705] Step 19800 per-step time 0.455s\nI1018 03:57:05.510788 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.1897456,\n 'Loss/localization_loss': 0.08076608,\n 'Loss/regularization_loss': 0.15399168,\n 'Loss/total_loss': 0.4245034,\n 'learning_rate': 0.004836321}\nI1018 03:57:50.985083 140662142089024 model_lib_v2.py:705] Step 19900 per-step time 0.455s\nI1018 03:57:50.985395 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.25441745,\n 'Loss/localization_loss': 0.11821981,\n 'Loss/regularization_loss': 0.1535611,\n 'Loss/total_loss': 0.5261984,\n 'learning_rate': 0.004659617}\nI1018 03:58:36.618298 140662142089024 model_lib_v2.py:705] Step 20000 per-step time 0.456s\nI1018 03:58:36.618661 140662142089024 model_lib_v2.py:708] {'Loss/classification_loss': 0.22433099,\n 'Loss/localization_loss': 0.0463883,\n 'Loss/regularization_loss': 0.1531891,\n 'Loss/total_loss': 0.42390835,\n 'learning_rate': 0.004485774}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"VALIDATION","metadata":{"id":"yZyIW2gkiDn8"}},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --model_dir={model_dir} \\\n    --checkpoint_dir={model_dir}","metadata":{"id":"2u4SQOjjiFNt","outputId":"85be44f9-b979-47a4-ebae-74f593318ebe","execution":{"iopub.status.busy":"2023-10-18T03:58:45.689105Z","iopub.execute_input":"2023-10-18T03:58:45.689328Z","iopub.status.idle":"2023-10-18T04:13:04.133874Z","shell.execute_reply.started":"2023-10-18T03:58:45.689306Z","shell.execute_reply":"2023-10-18T04:13:04.132948Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nW1018 03:58:51.418525 136436390848320 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\nI1018 03:58:51.418763 136436390848320 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\nI1018 03:58:51.418865 136436390848320 config_util.py:552] Maybe overwriting use_bfloat16: False\nI1018 03:58:51.418983 136436390848320 config_util.py:552] Maybe overwriting eval_num_epochs: 1\nW1018 03:58:51.419117 136436390848320 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\nI1018 03:58:53.981819 136436390848320 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/input/tfrecord/test.tfrecord']\nI1018 03:58:53.984991 136436390848320 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/input/tfrecord/test.tfrecord']\nI1018 03:58:53.985117 136436390848320 dataset_builder.py:80] Number of filenames to read: 1\nW1018 03:58:53.985179 136436390848320 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW1018 03:58:53.988823 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW1018 03:58:54.007462 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW1018 03:58:57.248418 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW1018 03:58:58.289186 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI1018 03:59:00.602421 136436390848320 checkpoint_utils.py:168] Waiting for new checkpoint at /kaggle/working/training/\nI1018 03:59:00.603175 136436390848320 checkpoint_utils.py:177] Found new checkpoint at /kaggle/working/training/ckpt-21\n/opt/conda/lib/python3.10/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn(\nI1018 03:59:08.205037 136436390848320 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 03:59:21.057645 136436390848320 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nW1018 03:59:29.767106 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI1018 03:59:29.792593 136436390848320 model_lib_v2.py:966] Finished eval step 0\nW1018 03:59:29.925313 136436390848320 deprecation.py:364] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nI1018 03:59:41.582049 136436390848320 model_lib_v2.py:966] Finished eval step 100\nI1018 03:59:52.456865 136436390848320 model_lib_v2.py:966] Finished eval step 200\nI1018 04:00:03.247239 136436390848320 model_lib_v2.py:966] Finished eval step 300\nI1018 04:00:14.391663 136436390848320 model_lib_v2.py:966] Finished eval step 400\nI1018 04:00:25.005857 136436390848320 model_lib_v2.py:966] Finished eval step 500\nI1018 04:00:35.630170 136436390848320 model_lib_v2.py:966] Finished eval step 600\nI1018 04:00:46.248205 136436390848320 model_lib_v2.py:966] Finished eval step 700\nI1018 04:00:56.789583 136436390848320 model_lib_v2.py:966] Finished eval step 800\nI1018 04:01:07.477167 136436390848320 model_lib_v2.py:966] Finished eval step 900\nI1018 04:01:18.219388 136436390848320 model_lib_v2.py:966] Finished eval step 1000\nI1018 04:01:28.767592 136436390848320 model_lib_v2.py:966] Finished eval step 1100\nI1018 04:01:39.696126 136436390848320 model_lib_v2.py:966] Finished eval step 1200\nI1018 04:01:50.393862 136436390848320 model_lib_v2.py:966] Finished eval step 1300\nI1018 04:02:01.018082 136436390848320 model_lib_v2.py:966] Finished eval step 1400\nI1018 04:02:11.619266 136436390848320 model_lib_v2.py:966] Finished eval step 1500\nI1018 04:02:22.319841 136436390848320 model_lib_v2.py:966] Finished eval step 1600\nI1018 04:02:32.907908 136436390848320 model_lib_v2.py:966] Finished eval step 1700\nI1018 04:02:43.465035 136436390848320 model_lib_v2.py:966] Finished eval step 1800\nI1018 04:02:54.133349 136436390848320 model_lib_v2.py:966] Finished eval step 1900\nI1018 04:03:04.770182 136436390848320 model_lib_v2.py:966] Finished eval step 2000\nI1018 04:03:15.439680 136436390848320 model_lib_v2.py:966] Finished eval step 2100\nI1018 04:03:26.373880 136436390848320 model_lib_v2.py:966] Finished eval step 2200\nI1018 04:03:36.936186 136436390848320 model_lib_v2.py:966] Finished eval step 2300\nI1018 04:03:47.574726 136436390848320 model_lib_v2.py:966] Finished eval step 2400\nI1018 04:03:58.184714 136436390848320 model_lib_v2.py:966] Finished eval step 2500\nI1018 04:04:08.851172 136436390848320 model_lib_v2.py:966] Finished eval step 2600\nI1018 04:04:19.560806 136436390848320 model_lib_v2.py:966] Finished eval step 2700\nI1018 04:04:30.143578 136436390848320 model_lib_v2.py:966] Finished eval step 2800\nI1018 04:04:40.733736 136436390848320 model_lib_v2.py:966] Finished eval step 2900\nI1018 04:04:51.400203 136436390848320 model_lib_v2.py:966] Finished eval step 3000\nI1018 04:05:01.981752 136436390848320 model_lib_v2.py:966] Finished eval step 3100\nI1018 04:05:12.636689 136436390848320 model_lib_v2.py:966] Finished eval step 3200\nI1018 04:05:23.403014 136436390848320 model_lib_v2.py:966] Finished eval step 3300\nI1018 04:05:34.388829 136436390848320 model_lib_v2.py:966] Finished eval step 3400\nI1018 04:05:44.992331 136436390848320 model_lib_v2.py:966] Finished eval step 3500\nI1018 04:05:55.699765 136436390848320 model_lib_v2.py:966] Finished eval step 3600\nI1018 04:06:06.328485 136436390848320 model_lib_v2.py:966] Finished eval step 3700\nI1018 04:06:16.956821 136436390848320 model_lib_v2.py:966] Finished eval step 3800\nI1018 04:06:27.667481 136436390848320 model_lib_v2.py:966] Finished eval step 3900\nI1018 04:06:38.262754 136436390848320 model_lib_v2.py:966] Finished eval step 4000\nI1018 04:06:48.794526 136436390848320 model_lib_v2.py:966] Finished eval step 4100\nI1018 04:06:59.505206 136436390848320 model_lib_v2.py:966] Finished eval step 4200\nI1018 04:07:10.142318 136436390848320 model_lib_v2.py:966] Finished eval step 4300\nI1018 04:07:20.693203 136436390848320 model_lib_v2.py:966] Finished eval step 4400\nI1018 04:07:31.369029 136436390848320 model_lib_v2.py:966] Finished eval step 4500\nI1018 04:07:41.995538 136436390848320 model_lib_v2.py:966] Finished eval step 4600\nI1018 04:07:52.523403 136436390848320 model_lib_v2.py:966] Finished eval step 4700\nI1018 04:08:03.172070 136436390848320 model_lib_v2.py:966] Finished eval step 4800\nI1018 04:08:13.739408 136436390848320 model_lib_v2.py:966] Finished eval step 4900\nI1018 04:08:24.716106 136436390848320 model_lib_v2.py:966] Finished eval step 5000\nI1018 04:08:35.421077 136436390848320 model_lib_v2.py:966] Finished eval step 5100\nI1018 04:08:45.958778 136436390848320 model_lib_v2.py:966] Finished eval step 5200\nI1018 04:08:56.524156 136436390848320 model_lib_v2.py:966] Finished eval step 5300\nI1018 04:09:07.204587 136436390848320 model_lib_v2.py:966] Finished eval step 5400\nI1018 04:09:17.787302 136436390848320 model_lib_v2.py:966] Finished eval step 5500\nI1018 04:09:28.318054 136436390848320 model_lib_v2.py:966] Finished eval step 5600\nI1018 04:09:38.999747 136436390848320 model_lib_v2.py:966] Finished eval step 5700\nI1018 04:09:49.558843 136436390848320 model_lib_v2.py:966] Finished eval step 5800\nI1018 04:10:00.131791 136436390848320 model_lib_v2.py:966] Finished eval step 5900\nI1018 04:10:10.836006 136436390848320 model_lib_v2.py:966] Finished eval step 6000\nI1018 04:10:21.367161 136436390848320 model_lib_v2.py:966] Finished eval step 6100\nI1018 04:10:31.922405 136436390848320 model_lib_v2.py:966] Finished eval step 6200\nI1018 04:10:42.747358 136436390848320 model_lib_v2.py:966] Finished eval step 6300\nI1018 04:10:53.444712 136436390848320 model_lib_v2.py:966] Finished eval step 6400\nI1018 04:11:04.252707 136436390848320 model_lib_v2.py:966] Finished eval step 6500\nI1018 04:11:15.101969 136436390848320 model_lib_v2.py:966] Finished eval step 6600\nI1018 04:11:25.795700 136436390848320 model_lib_v2.py:966] Finished eval step 6700\nI1018 04:12:22.814500 136436390848320 coco_evaluation.py:293] Performing evaluation on 6721 images.\ncreating index...\nindex created!\nI1018 04:12:22.832273 136436390848320 coco_tools.py:116] Loading and preparing annotation results...\nI1018 04:12:23.327180 136436390848320 coco_tools.py:138] DONE (t=0.49s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=25.00s).\nAccumulating evaluation results...\nDONE (t=12.24s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.568\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.478\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.627\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.710\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\nI1018 04:13:01.950058 136436390848320 model_lib_v2.py:1015] Eval metrics at step 20000\nI1018 04:13:01.956975 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.407335\nI1018 04:13:01.958457 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.567800\nI1018 04:13:01.959886 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.477648\nI1018 04:13:01.961187 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.150445\nI1018 04:13:01.962479 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.209048\nI1018 04:13:01.963749 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.481603\nI1018 04:13:01.965052 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.626637\nI1018 04:13:01.966360 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.710359\nI1018 04:13:01.967714 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.722384\nI1018 04:13:01.969013 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.421939\nI1018 04:13:01.970263 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.567109\nI1018 04:13:01.971613 136436390848320 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.792296\nI1018 04:13:01.972578 136436390848320 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.100735\nI1018 04:13:01.973682 136436390848320 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.270686\nI1018 04:13:01.974621 136436390848320 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.153184\nI1018 04:13:01.975573 136436390848320 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.524605\nI1018 04:13:02.335713 136436390848320 model_lib_v2.py:1168] Exiting evaluation at step 20000\n","output_type":"stream"}]},{"cell_type":"code","source":"output_directory = '/kaggle/working/inference_graph'\n\n!python /kaggle/working/models/research/object_detection/exporter_main_v2.py \\\n    --trained_checkpoint_dir={model_dir} \\\n    --output_directory={output_directory} \\\n    --pipeline_config_path={pipeline_config_path}","metadata":{"id":"rM6Opm4diIGu","outputId":"c8edbfcd-eb24-41e2-b4c5-3f295d2eff95","execution":{"iopub.status.busy":"2023-10-18T04:13:04.135155Z","iopub.execute_input":"2023-10-18T04:13:04.135644Z","iopub.status.idle":"2023-10-18T04:14:12.168281Z","shell.execute_reply.started":"2023-10-18T04:13:04.135617Z","shell.execute_reply":"2023-10-18T04:14:12.167239Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nW1018 04:13:11.600279 132464943462208 deprecation.py:641] From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\nInstructions for updating:\nback_prop=False is deprecated. Consider using tf.stop_gradient instead.\nInstead of:\nresults = tf.map_fn(fn, elems, back_prop=False)\nUse:\nresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\nI1018 04:13:17.623703 132464943462208 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 04:13:27.417870 132464943462208 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 04:13:31.644007 132464943462208 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\nI1018 04:13:33.677442 132464943462208 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nW1018 04:13:36.738136 132464943462208 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7879384872e0>, because it is not built.\nI1018 04:13:58.846700 132464943462208 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\nI1018 04:14:08.885637 132464943462208 builder_impl.py:804] Assets written to: /kaggle/working/inference_graph/saved_model/assets\nI1018 04:14:09.313039 132464943462208 fingerprinting_utils.py:48] Writing fingerprint to /kaggle/working/inference_graph/saved_model/fingerprint.pb\nI1018 04:14:10.000282 132464943462208 config_util.py:253] Writing pipeline config file to /kaggle/working/inference_graph/pipeline.config\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TFLITE**","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/export_tflite_graph_tf2.py \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --trained_checkpoint_dir /kaggle/working/training \\\n    --output_directory /kaggle/working/inference_graph_tflite","metadata":{"id":"mG9pjeU_iLTx","outputId":"91372a84-8e2c-4f51-f8fb-e4ad5062470e","execution":{"iopub.status.busy":"2023-10-18T04:14:12.169468Z","iopub.execute_input":"2023-10-18T04:14:12.169693Z","iopub.status.idle":"2023-10-18T04:15:09.412512Z","shell.execute_reply.started":"2023-10-18T04:14:12.169671Z","shell.execute_reply":"2023-10-18T04:15:09.411593Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nI1018 04:14:25.067687 139165023074112 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 04:14:29.833872 139165023074112 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nI1018 04:14:31.204815 139165023074112 signature_serialization.py:148] Function `inference_fn` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\nI1018 04:14:32.945961 139165023074112 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\nW1018 04:14:34.210969 139165023074112 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7e91340e6c20>, because it is not built.\nI1018 04:14:56.581162 139165023074112 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\nI1018 04:15:06.380887 139165023074112 builder_impl.py:804] Assets written to: /kaggle/working/inference_graph_tflite/saved_model/assets\nI1018 04:15:06.771474 139165023074112 fingerprinting_utils.py:48] Writing fingerprint to /kaggle/working/inference_graph_tflite/saved_model/fingerprint.pb\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/inference_graph_tflite\nimport tensorflow as tf\n\nconverter = tf.lite.TFLiteConverter.from_saved_model('/kaggle/working/inference_graph_tflite/saved_model') # path to the SavedModel directory\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\ntflite_model = converter.convert()\n# Save the TensorFlow Lite model to a file\nwith open('model17.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T04:15:09.413821Z","iopub.execute_input":"2023-10-18T04:15:09.414090Z","iopub.status.idle":"2023-10-18T04:15:54.034455Z","shell.execute_reply.started":"2023-10-18T04:15:09.414066Z","shell.execute_reply":"2023-10-18T04:15:54.033482Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/working/inference_graph_tflite\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r /kaggle/working/inference_graph.zip /kaggle/working/inference_graph/\n!zip -r /kaggle/working/inference_graph_tflite.zip /kaggle/working/inference_graph_tflite/\n!zip -r /kaggle/working/training.zip /kaggle/working/training/","metadata":{"id":"kXr1hH7dkBaI","outputId":"e293e578-4975-4228-b81f-5a23b6e51803","execution":{"iopub.status.busy":"2023-10-18T04:15:54.036629Z","iopub.execute_input":"2023-10-18T04:15:54.036881Z","iopub.status.idle":"2023-10-18T04:18:57.987863Z","shell.execute_reply.started":"2023-10-18T04:15:54.036860Z","shell.execute_reply":"2023-10-18T04:18:57.986890Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/inference_graph/ (stored 0%)\n  adding: kaggle/working/inference_graph/pipeline.config (deflated 68%)\n  adding: kaggle/working/inference_graph/saved_model/ (stored 0%)\n  adding: kaggle/working/inference_graph/saved_model/fingerprint.pb (stored 0%)\n  adding: kaggle/working/inference_graph/saved_model/assets/ (stored 0%)\n  adding: kaggle/working/inference_graph/saved_model/saved_model.pb (deflated 93%)\n  adding: kaggle/working/inference_graph/saved_model/variables/ (stored 0%)\n  adding: kaggle/working/inference_graph/saved_model/variables/variables.index (deflated 81%)\n  adding: kaggle/working/inference_graph/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n  adding: kaggle/working/inference_graph/checkpoint/ (stored 0%)\n  adding: kaggle/working/inference_graph/checkpoint/ckpt-0.index (deflated 82%)\n  adding: kaggle/working/inference_graph/checkpoint/ckpt-0.data-00000-of-00001 (deflated 7%)\n  adding: kaggle/working/inference_graph/checkpoint/checkpoint (deflated 41%)\n  adding: kaggle/working/inference_graph_tflite/ (stored 0%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/ (stored 0%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/fingerprint.pb (stored 0%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/assets/ (stored 0%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/saved_model.pb (deflated 91%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/variables/ (stored 0%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/variables/variables.index (deflated 81%)\n  adding: kaggle/working/inference_graph_tflite/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n  adding: kaggle/working/inference_graph_tflite/model17.tflite (deflated 16%)\n  adding: kaggle/working/training/ (stored 0%)\n  adding: kaggle/working/training/ckpt-15.index (deflated 84%)\n  adding: kaggle/working/training/ckpt-19.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/ckpt-18.index (deflated 84%)\n  adding: kaggle/working/training/ckpt-20.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/ckpt-20.index (deflated 84%)\n  adding: kaggle/working/training/ckpt-21.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/train/ (stored 0%)\n  adding: kaggle/working/training/train/events.out.tfevents.1697592219.515ee452d650.208.0.v2 (deflated 2%)\n  adding: kaggle/working/training/ckpt-18.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/ckpt-17.index (deflated 84%)\n  adding: kaggle/working/training/eval/ (stored 0%)\n  adding: kaggle/working/training/eval/events.out.tfevents.1697601540.515ee452d650.456.0.v2 (deflated 1%)\n  adding: kaggle/working/training/ckpt-19.index (deflated 84%)\n  adding: kaggle/working/training/ckpt-21.index (deflated 84%)\n  adding: kaggle/working/training/checkpoint (deflated 76%)\n  adding: kaggle/working/training/ckpt-17.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/ckpt-16.index (deflated 84%)\n  adding: kaggle/working/training/ckpt-15.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/training/ckpt-16.data-00000-of-00001 (deflated 6%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TENSORBOARD**","metadata":{}},{"cell_type":"markdown","source":"%load_ext tensorboard\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ./ngrok-stable-linux-amd64.zip\n!./ngrok authtoken 2WR6sz0LL5J47kwf2UYMNr1L1fG_7AGSSvhLnEBtEGNvyz8Bw #ganti authken e signup ng ngrok","metadata":{"execution":{"iopub.status.busy":"2023-10-12T11:42:27.902757Z","iopub.execute_input":"2023-10-12T11:42:27.903172Z","iopub.status.idle":"2023-10-12T11:42:32.056997Z","shell.execute_reply.started":"2023-10-12T11:42:27.903139Z","shell.execute_reply":"2023-10-12T11:42:32.055643Z"}}},{"cell_type":"markdown","source":" # Launch and tunnel tensorboard\nimport os\nimport multiprocessing\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir /kaggle/working/training --host 0.0.0.0 --port 6009 &\",\n                        \"./ngrok http 6009 &\"\n                        ]]","metadata":{"execution":{"iopub.status.busy":"2023-10-12T11:42:34.445842Z","iopub.execute_input":"2023-10-12T11:42:34.446264Z","iopub.status.idle":"2023-10-12T11:42:35.013146Z","shell.execute_reply.started":"2023-10-12T11:42:34.446226Z","shell.execute_reply":"2023-10-12T11:42:35.010516Z"}}},{"cell_type":"markdown","source":"import time\ntime.sleep(10) # wait for tensorboard host\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"execution":{"iopub.status.busy":"2023-10-12T11:42:44.270210Z","iopub.execute_input":"2023-10-12T11:42:44.270867Z","iopub.status.idle":"2023-10-12T11:42:55.495449Z","shell.execute_reply.started":"2023-10-12T11:42:44.270828Z","shell.execute_reply":"2023-10-12T11:42:55.493735Z"}}},{"cell_type":"markdown","source":"****TESTING****","metadata":{}},{"cell_type":"markdown","source":"import os\nimport subprocess\nfrom collections import namedtuple\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","metadata":{"id":"amqp5VcMjZ3e"}},{"cell_type":"markdown","source":"%cd /kaggle/working/","metadata":{}},{"cell_type":"markdown","source":"!wget https://raw.githubusercontent.com/hugozanini/object-detection/master/inferenceutils.py","metadata":{}},{"cell_type":"markdown","source":"import sys\n\nsys.path.insert(0, '/kaggle/working/')\n\nfrom inferenceutils import *","metadata":{}},{"cell_type":"markdown","source":"output_directory = 'inference_graph/'","metadata":{}},{"cell_type":"markdown","source":"category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\ntf.keras.backend.clear_session()\nmodel = tf.saved_model.load(f'/kaggle/working/{output_directory}/saved_model')","metadata":{}},{"cell_type":"markdown","source":"images = [\"0156.jpg\", \"0240.jpg\", \"0422.jpg\"]\n\nfor image_name in images:\n    image_np = load_image_into_numpy_array('/kaggle/input/testing/' + image_name)\n    output_dict = run_inference_for_single_image(model, image_np)\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        image_np,\n        output_dict['detection_boxes'],\n        output_dict['detection_classes'],\n        output_dict['detection_scores'],\n        category_index,\n        instance_masks = output_dict.get('detection_masks_reframed', None),\n        use_normalized_coordinates = True,\n        min_score_thresh = .46,\n        line_thickness = 6)\n    display(Image.fromarray(image_np))","metadata":{}},{"cell_type":"markdown","source":"import os\nimport time\nimport tensorflow as tf\nimport cv2\nimport numpy as np\n\nfrom object_detection.utils import label_map_util\nfrom PIL import Image\n#from google.colab.patches import cv2_imshow\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as viz_utils\n\nfrom IPython.display import HTML\nfrom base64 import b64encode\n\n#Path to saved model\n\nPATH_TO_SAVED_MODEL = \"/kaggle/working/inference_graph/saved_model\"\n\n# Load label map and obtain class names and ids\n#label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategory_index=label_map_util.create_category_index_from_labelmap(\"/kaggle/input/images2/images/labelmap.pbtxt\",use_display_name=True)\nnum_detect = [0,0,0,0]\n\ndef visualise_on_image(image, bboxes, labels, scores, thresh):\n    (h, w, d) = image.shape\n    for bbox, label, score in zip(bboxes, labels, scores):\n        if score > thresh:\n            xmin, ymin = int(bbox[1]*w), int(bbox[0]*h)\n            xmax, ymax = int(bbox[3]*w), int(bbox[2]*h)\n\n            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n            cv2.putText(image, f\"{label}: {int(score*100)} %\", (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 2)\n            if label == \"R02\":\n              num_detect[0] += 1\n              cv2.putText(image, f\"1: {num_detect[0]}\", (50,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)\n            if label == \"R03\":\n              num_detect[1] += 1\n              cv2.putText(image, f\"2: {num_detect[1]}\", (60,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)\n            if label == \"L00\":\n              num_detect[2] += 1\n              cv2.putText(image, f\"3: {num_detect[2]}\", (70,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)\n            if label == \"00\":\n              num_detect[3] += 1\n              cv2.putText(image, f\"4: {num_detect[3]}\", (80,70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (182, 3, 252), 2)\n            #print(label)\n            #print(type(label))\n    return image\n\nif __name__ == '__main__':\n\n    # Load the model\n    print(\"Loading saved model ...\")\n    detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n    print(\"Model Loaded!\")\n\n    # Video Capture (video_file)\n    video_capture = cv2.VideoCapture(\"/kaggle/input/videotesting/output_test.avi\")\n    start_time = time.time()\n\n    frame_width = int(video_capture.get(3))\n    frame_height = int(video_capture.get(4))\n    #fps = int(video_capture.get(5))\n    size = (frame_width, frame_height)\n\n    #Initialize video writer\n    result = cv2.VideoWriter('/kaggle/working/output_test.avi', cv2.VideoWriter_fourcc(*'MJPG'),15, size)\n\n    while True:\n      ret, frame = video_capture.read()\n      if not ret:\n          print('Unable to read video / Video ended')\n          break\n\n      frame = cv2.flip(frame, 1)\n      image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n      # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n      # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n      input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n\n      # Pass frame through detector\n      detections = detect_fn(input_tensor)\n\n      # Set detection parameters\n\n      score_thresh = 0.4   # Minimum threshold for object detection\n      max_detections = 100\n\n      # All outputs are batches tensors.\n      # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n      # We're only interested in the first num_detections.\n      scores = detections['detection_scores'][0, :max_detections].numpy()\n      bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n      labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n      labels = [category_index[n]['name'] for n in labels]\n\n      # Display detections\n      visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n\n      end_time = time.time()\n      fps = int(1/(end_time - start_time))\n      start_time = end_time\n      cv2.putText(frame, f\"FPS: {fps}\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n      #cv2_imshow(frame)\n      #print ([category_index.get(value) for index,value in enumerate(labels[0]) if scores[0] > 0.4])\n      #Write output video\n      result.write(frame)\n\n    for i in num_detect:\n        print(i, end=\" \")\n    video_capture.release()","metadata":{}}]}